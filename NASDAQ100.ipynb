{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a1f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mkt_Cap</th>\n",
       "      <th>Mkt_Cap_SOM</th>\n",
       "      <th>TR</th>\n",
       "      <th>NTM_RevGrowth_EOM</th>\n",
       "      <th>2y_RevGrowth_EOM</th>\n",
       "      <th>NTM_RevGrowth_3mChg_SOM</th>\n",
       "      <th>NTM_Rev_3mChg_SOM</th>\n",
       "      <th>NTM_EBITDA_Margin_EOM</th>\n",
       "      <th>...</th>\n",
       "      <th>PB_TTM</th>\n",
       "      <th>BY_1y_Fwd</th>\n",
       "      <th>PB_1y_Fwd</th>\n",
       "      <th>BY_2y_Fwd</th>\n",
       "      <th>PB_2y_Fwd</th>\n",
       "      <th>DY_TTM</th>\n",
       "      <th>DY_1y_Fwd</th>\n",
       "      <th>DY_2y_Fwd</th>\n",
       "      <th>NOSH_Chg_LTM</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>CA0019411036</td>\n",
       "      <td>4436.90</td>\n",
       "      <td>4361.09</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>0.138046</td>\n",
       "      <td>-0.010410</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.142151</td>\n",
       "      <td>...</td>\n",
       "      <td>4.368812</td>\n",
       "      <td>0.284683</td>\n",
       "      <td>3.512677</td>\n",
       "      <td>0.357776</td>\n",
       "      <td>2.795048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>US00724F1012</td>\n",
       "      <td>15079.35</td>\n",
       "      <td>13894.97</td>\n",
       "      <td>0.085238</td>\n",
       "      <td>0.135985</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>0.016468</td>\n",
       "      <td>0.068849</td>\n",
       "      <td>0.381916</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609966</td>\n",
       "      <td>0.105166</td>\n",
       "      <td>9.508817</td>\n",
       "      <td>0.136223</td>\n",
       "      <td>7.340895</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>US0214411003</td>\n",
       "      <td>7721.47</td>\n",
       "      <td>7148.02</td>\n",
       "      <td>0.080208</td>\n",
       "      <td>0.049373</td>\n",
       "      <td>0.101459</td>\n",
       "      <td>-0.121627</td>\n",
       "      <td>-0.105779</td>\n",
       "      <td>0.309555</td>\n",
       "      <td>...</td>\n",
       "      <td>6.029070</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>5.268282</td>\n",
       "      <td>0.189007</td>\n",
       "      <td>5.290816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>42362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>US0231351067</td>\n",
       "      <td>14355.26</td>\n",
       "      <td>17636.00</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>0.204210</td>\n",
       "      <td>0.186766</td>\n",
       "      <td>-0.036280</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.078614</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>1337.572917</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>24.118520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>US0290661075</td>\n",
       "      <td>4211.67</td>\n",
       "      <td>4068.22</td>\n",
       "      <td>0.039988</td>\n",
       "      <td>0.108367</td>\n",
       "      <td>0.105543</td>\n",
       "      <td>-0.007343</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.152153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.023615</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>39127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          ISIN   Mkt_Cap  Mkt_Cap_SOM        TR  \\\n",
       "0 2005-02-28  CA0019411036   4436.90      4361.09  0.017381   \n",
       "1 2005-02-28  US00724F1012  15079.35     13894.97  0.085238   \n",
       "2 2005-02-28  US0214411003   7721.47      7148.02  0.080208   \n",
       "3 2005-02-28  US0231351067  14355.26     17636.00 -0.186023   \n",
       "4 2005-02-28  US0290661075   4211.67      4068.22  0.039988   \n",
       "\n",
       "   NTM_RevGrowth_EOM  2y_RevGrowth_EOM  NTM_RevGrowth_3mChg_SOM  \\\n",
       "0           0.184159          0.138046                -0.010410   \n",
       "1           0.135985          0.147171                 0.016468   \n",
       "2           0.049373          0.101459                -0.121627   \n",
       "3           0.204210          0.186766                -0.036280   \n",
       "4           0.108367          0.105543                -0.007343   \n",
       "\n",
       "   NTM_Rev_3mChg_SOM  NTM_EBITDA_Margin_EOM  ...     PB_TTM  BY_1y_Fwd  \\\n",
       "0           0.057844               0.142151  ...   4.368812   0.284683   \n",
       "1           0.068849               0.381916  ...  10.609966   0.105166   \n",
       "2          -0.105779               0.309555  ...   6.029070   0.189815   \n",
       "3           0.023195               0.078614  ...        NaN   0.000748   \n",
       "4           0.023354               0.152153  ...        NaN        NaN   \n",
       "\n",
       "     PB_1y_Fwd  BY_2y_Fwd  PB_2y_Fwd    DY_TTM  DY_1y_Fwd  DY_2y_Fwd  \\\n",
       "0     3.512677   0.357776   2.795048  0.000000   0.000000   0.000000   \n",
       "1     9.508817   0.136223   7.340895  0.000874   0.001052   0.001375   \n",
       "2     5.268282   0.189007   5.290816       NaN        NaN        NaN   \n",
       "3  1337.572917   0.041462  24.118520       NaN        NaN        NaN   \n",
       "4          NaN        NaN        NaN  0.016803   0.019808   0.023615   \n",
       "\n",
       "   NOSH_Chg_LTM   TIME  \n",
       "0      0.000000  39014  \n",
       "1      0.000000  45580  \n",
       "2      0.009407  42362  \n",
       "3      0.000000  45580  \n",
       "4      0.036882  39127  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## Define file path depending on which index to examine\n",
    "\n",
    "## S&P500\n",
    "index_file_path = \"H:/Tech Hardware Shared/$Mike/Quant/NASA100_Constit.csv\"\n",
    "csv_directory = \"H:/Tech Hardware Shared/$Mike/Quant/CSV_files\"\n",
    "export_path = \"H:/Tech Hardware Shared/$Mike/Quant/Python_Outputs/\"\n",
    "export_audit_file_name = 'NASA100_audit.xlsx'\n",
    "export_index_file_name = 'NASA100_Index_Avgs.xlsx'\n",
    "export_LS_file_name = 'NASA100_LS.xlsx'\n",
    "export_dispersion_file_name = 'NASA100_dispersion.xlsx'\n",
    "export_examine_CSV_file_name = 'NASA100_indiv_CSV.xlsx'\n",
    "\n",
    "##### CREATING DATABASE DATAFRAME ######\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(index_file_path, header=0)\n",
    "# Convert the column names to datetime with the given format\n",
    "df.columns = pd.to_datetime(df.columns, format='%d-%b-%y')\n",
    "\n",
    "# Melt the DataFrame to reshape it\n",
    "df = pd.melt(df, id_vars=[], var_name='Date', value_name='ISIN')\n",
    "df['Date'] = df['Date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# Use a placeholder for NaN values in the 'ISIN' column \n",
    "df['ISIN'].fillna('placeholder', inplace=True)\n",
    "\n",
    "# Create a list to store each ISIN's data\n",
    "all_isin_data = []\n",
    "\n",
    "# Iterate through each ISIN in the 'ISIN' column \n",
    "for isin in df['ISIN'].unique():\n",
    "    # Skip if the ISIN is 'placeholder'\n",
    "    if isin != 'placeholder':\n",
    "        # Construct the file path for the CSV file\n",
    "        index_file_path = os.path.join(csv_directory, f'{isin}.csv')\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(index_file_path):        \n",
    "            # Read the CSV file\n",
    "            isin_data = pd.read_csv(index_file_path, header=0)  # Assuming header is in row 2 and 'Date' is the label\n",
    "            isin_data['Date'] = pd.to_datetime(isin_data['Date'], unit='D', origin='1899-12-30')\n",
    "            isin_data['Date'] = isin_data['Date'] + pd.offsets.MonthEnd(0)\n",
    "            isin_data['ISIN'] = isin\n",
    "            # Convert all data columns to numeric\n",
    "                                  \n",
    "            numeric_columns = ['Mkt_Cap','TR', 'PCH',\n",
    "                               'NTM_RevGrowth','2y_RevGrowth',\n",
    "                               'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                               'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                               'CoE', 'Assumed_G', \n",
    "                               'Sales_EV_1y_Fwd', 'EV_Sales_1y_Fwd', 'EBITDA_EV_1y_Fwd','EV_EBITDA_1y_Fwd',\n",
    "                               'EY_TTM','PE_TTM', 'EY_1y_Fwd','PE_1y_Fwd','EY_2y_Fwd','PE_2y_Fwd',\n",
    "                               'BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd',\n",
    "                               'DY_TTM','DY_1y_Fwd','DY_2y_Fwd',\n",
    "                               'NOSH_Chg_LTM',\n",
    "                               'TIME',\n",
    "                               'Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                               'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM',\n",
    "                               'NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                               'NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                               'Sales_EV_1y_Fwd_SOM','EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "            isin_data[numeric_columns] = isin_data[numeric_columns].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            # nix out negative BVPS data & other floors / ceilings\n",
    "            neg_cols = ['BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd','CoE']\n",
    "            for col in neg_cols:\n",
    "                isin_data[col] = np.where(isin_data[col] < 0, np.nan, isin_data[col])\n",
    "            \n",
    "            upper_bound = 0.5 # Max CoE = 50%\n",
    "            isin_data['CoE'] = isin_data['CoE'].clip(upper=upper_bound)\n",
    "                                   \n",
    "            lower_bound = -0.02 # Max multiple = -50x\n",
    "            upper_bound = 1 # Min multiple = 1x\n",
    "            isin_data['Sales_EV_1y_Fwd'] = isin_data['Sales_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EBITDA_EV_1y_Fwd'] = isin_data['EBITDA_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_TTM'] = isin_data['EY_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_1y_Fwd'] = isin_data['EY_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_2y_Fwd'] = isin_data['EY_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            \n",
    "            lower_bound = -0.5\n",
    "            upper_bound = 1.5\n",
    "            isin_data['RoE_TTM'] = isin_data['RoE_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_1y_Fwd'] = isin_data['RoE_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_2y_Fwd'] = isin_data['RoE_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "                                        \n",
    "            # Append the data to the list\n",
    "            all_isin_data.append(isin_data)\n",
    "\n",
    "# Concatenate all ISIN data into a single DataFrame\n",
    "isin_final_df = pd.concat(all_isin_data, ignore_index=True)\n",
    "\n",
    "# Merge the additional columns into the melted DataFrame using 'Date' and 'ISIN' as the keys \n",
    "df = pd.merge(df, isin_final_df, on=['Date','ISIN'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "#full_export_path = export_path + export_audit_file_name\n",
    "#df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE DATAFRAME OF EQUAL WEIGHTED AND MARKET CAP WEIGHTED AVERAGE RATIOS ####\n",
    "\n",
    "\n",
    "### Equal Weight Calculation\n",
    "EqualWeightIndex_df = df.groupby('Date')[['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].mean().reset_index()\n",
    "\n",
    "EqualWeightIndex_df.columns = [f'{col}_Eq_Wgt' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in EqualWeightIndex_df.columns]\n",
    "\n",
    "EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['Sales_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EBITDA_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_2y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_2y_Fwd_Eq_Wgt']\n",
    "\n",
    "\n",
    "### Median Weight Calculation\n",
    "MedianIndex_df = df.groupby('Date')[['TR',\n",
    "                                     'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                     'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                     'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                     'CoE', 'Assumed_G',\n",
    "                                     'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                     'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                     'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                     'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].median().reset_index()\n",
    "\n",
    "MedianIndex_df.columns = [f'{col}_Median' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in MedianIndex_df.columns]\n",
    "\n",
    "MedianIndex_df['EV_Sales_1y_Fwd_Median'] = 1/MedianIndex_df['Sales_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['EV_EBITDA_1y_Fwd_Median'] = 1/MedianIndex_df['EBITDA_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_TTM_Median'] = 1/MedianIndex_df['EY_TTM_Median']\n",
    "MedianIndex_df['PE_1y_Fwd_Median'] = 1/MedianIndex_df['EY_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_2y_Fwd_Median'] = 1/MedianIndex_df['EY_2y_Fwd_Median']\n",
    "MedianIndex_df['PB_TTM_Median'] = 1/MedianIndex_df['BY_TTM_Median']\n",
    "MedianIndex_df['PB_1y_Fwd_Median'] = 1/MedianIndex_df['BY_1y_Fwd_Median']\n",
    "MedianIndex_df['PB_2y_Fwd_Median'] = 1/MedianIndex_df['BY_2y_Fwd_Median']\n",
    "\n",
    "### MKT CAP WEIGHTED CALCULATION\n",
    "\n",
    "# Step 1: Create a function for weighted average calculation\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    valid_entries = ~df[value_col].isna()\n",
    "    weights = df.loc[valid_entries, weight_col]\n",
    "    values = df.loc[valid_entries, value_col]\n",
    "    if weights.sum() == 0:\n",
    "        # Handle the case where denominator is zero\n",
    "        return 0\n",
    "    else:\n",
    "        weighted_avg = (weights * values).sum() / weights.sum()\n",
    "        return weighted_avg\n",
    "\n",
    "# Step 2: Create a function to calculate the market cap weighted averages\n",
    "def calculate_weighted_averages(group):\n",
    "    weighted_TR = weighted_average(group, 'TR', 'Mkt_Cap_SOM')\n",
    "    weighted_NTM_RevGrowth = weighted_average(group, 'NTM_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_2y_RevGrowth = weighted_average(group, '2y_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_NTM_EBITDA_Margin = weighted_average(group, 'NTM_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_2y_EBITDA_Margin = weighted_average(group, '2y_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_RoE_TTM = weighted_average(group, 'RoE_TTM', 'Mkt_Cap')\n",
    "    weighted_RoE_1y_Fwd = weighted_average(group, 'RoE_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_RoE_2y_Fwd = weighted_average(group, 'RoE_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_CoE = weighted_average(group, 'CoE', 'Mkt_Cap')\n",
    "    weighted_Assumed_G = weighted_average(group, 'Assumed_G', 'Mkt_Cap')\n",
    "    weighted_Sales_EV_1y_Fwd = weighted_average(group, 'Sales_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EBITDA_EV_1y_Fwd = weighted_average(group, 'EBITDA_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_TTM = weighted_average(group, 'EY_TTM', 'Mkt_Cap')\n",
    "    weighted_EY_1y_Fwd = weighted_average(group, 'EY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_2y_Fwd = weighted_average(group, 'EY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_BY_TTM = weighted_average(group, 'BY_TTM', 'Mkt_Cap')\n",
    "    weighted_BY_1y_Fwd = weighted_average(group, 'BY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_BY_2y_Fwd = weighted_average(group, 'BY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_DY_TTM = weighted_average(group, 'DY_TTM', 'Mkt_Cap')\n",
    "    weighted_DY_1y_Fwd = weighted_average(group, 'DY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_DY_2y_Fwd = weighted_average(group, 'DY_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_NOSH_Chg_LTM = weighted_average(group, 'NOSH_Chg_LTM', 'Mkt_Cap')\n",
    "    \n",
    "    \n",
    "    return pd.Series({\n",
    "        'TR_MV_Wgt': weighted_TR,\n",
    "        'NTM_RevGrowth_MV_Wgt': weighted_NTM_RevGrowth,\n",
    "        '2y_RevGrowth_MV_Wgt': weighted_2y_RevGrowth,\n",
    "        'NTM_EBITDA_Margin_MV_Wgt': weighted_NTM_EBITDA_Margin,\n",
    "        '2y_EBITDA_Margin_MV_Wgt': weighted_2y_EBITDA_Margin,\n",
    "        'RoE_TTM_MV_Wgt': weighted_RoE_TTM,\n",
    "        'RoE_1y_Fwd_MV_Wgt': weighted_RoE_1y_Fwd,\n",
    "        'RoE_2y_Fwd_MV_Wgt': weighted_RoE_2y_Fwd,\n",
    "        'CoE_MV_Wgt': weighted_CoE,\n",
    "        'Assumed_G_MV_Wgt': weighted_Assumed_G,\n",
    "        'EV_Sales_1y_Fwd_MV_Wgt': weighted_Sales_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'EV_EBITDA_1y_Fwd_MV_Wgt': weighted_EBITDA_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_TTM_MV_Wgt': weighted_EY_TTM, # execution of reciprocal below\n",
    "        'PE_1y_Fwd_MV_Wgt': weighted_EY_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_2y_Fwd_MV_Wgt': weighted_EY_2y_Fwd, # execution of reciprocal below\n",
    "        'PB_TTM_MV_Wgt': weighted_BY_TTM, # execution of reciprocal below\n",
    "        'PB_1y_Fwd_MV_Wgt': weighted_BY_1y_Fwd, # execution of reciprocal below\n",
    "        'PB_2y_Fwd_MV_Wgt': weighted_BY_2y_Fwd, # execution of reciprocal below\n",
    "        'DY_TTM_MV_Wgt': weighted_DY_TTM,\n",
    "        'DY_1y_Fwd_MV_Wgt': weighted_DY_1y_Fwd,\n",
    "        'DY_2y_Fwd_MV_Wgt': weighted_DY_2y_Fwd,\n",
    "        'NOSH_Chg_LTM_MV_Wgt': weighted_NOSH_Chg_LTM\n",
    "    })\n",
    "\n",
    "# Step 3: Apply the calculation to your DataFrame\n",
    "Index_df = df.groupby('Date').apply(calculate_weighted_averages).reset_index()\n",
    "Index_df['EV_Sales_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_Sales_1y_Fwd_MV_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_EBITDA_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_TTM_MV_Wgt'] = 1/Index_df['PE_TTM_MV_Wgt']\n",
    "Index_df['PE_1y_Fwd_MV_Wgt'] = 1/Index_df['PE_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_2y_Fwd_MV_Wgt'] = 1/Index_df['PE_2y_Fwd_MV_Wgt']\n",
    "Index_df['PB_TTM_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_1y_Fwd_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_2y_Fwd_MV_Wgt'] = 1/Index_df['PB_2y_Fwd_MV_Wgt']\n",
    "\n",
    "# Step 4: Add in the equal weighted calculations from above into the Index dataframe\n",
    "Index_df['TR_Eq_Wgt'] = EqualWeightIndex_df['TR_Eq_Wgt']\n",
    "Index_df['NTM_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['NTM_RevGrowth_Eq_Wgt']\n",
    "Index_df['2y_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['2y_RevGrowth_Eq_Wgt']\n",
    "Index_df['NTM_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['NTM_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['2y_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['2y_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['RoE_TTM_Eq_Wgt'] = EqualWeightIndex_df['RoE_TTM_Eq_Wgt']\n",
    "Index_df['RoE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['RoE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['CoE_Eq_Wgt'] = EqualWeightIndex_df['CoE_Eq_Wgt']\n",
    "Index_df['Assumed_G_Eq_Wgt'] = EqualWeightIndex_df['Assumed_G_Eq_Wgt']\n",
    "Index_df['EV_Sales_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_TTM_Eq_Wgt'] = EqualWeightIndex_df['PE_TTM_Eq_Wgt']\n",
    "Index_df['PE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_TTM_Eq_Wgt'] = EqualWeightIndex_df['PB_TTM_Eq_Wgt']\n",
    "Index_df['PB_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_TTM_Eq_Wgt'] = EqualWeightIndex_df['DY_TTM_Eq_Wgt']\n",
    "Index_df['DY_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_1y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_2y_Fwd_Eq_Wgt']\n",
    "Index_df['NOSH_Chg_LTM_Eq_Wgt'] = EqualWeightIndex_df['NOSH_Chg_LTM_Eq_Wgt']\n",
    "\n",
    "# Step 5: Add in the median calculations from above into the Index dataframe\n",
    "Index_df['TR_Median'] = MedianIndex_df['TR_Median']\n",
    "Index_df['NTM_RevGrowth_Median'] = MedianIndex_df['NTM_RevGrowth_Median']\n",
    "Index_df['2y_RevGrowth_Median'] = MedianIndex_df['2y_RevGrowth_Median']\n",
    "Index_df['NTM_EBITDA_Margin_Median'] = MedianIndex_df['NTM_EBITDA_Margin_Median']\n",
    "Index_df['2y_EBITDA_Margin_Median'] = MedianIndex_df['2y_EBITDA_Margin_Median']\n",
    "Index_df['RoE_TTM_Median'] = MedianIndex_df['RoE_TTM_Median']\n",
    "Index_df['RoE_1y_Fwd_Median'] = MedianIndex_df['RoE_1y_Fwd_Median']\n",
    "Index_df['RoE_2y_Fwd_Median'] = MedianIndex_df['RoE_2y_Fwd_Median']\n",
    "Index_df['CoE_Median'] = MedianIndex_df['CoE_Median']\n",
    "Index_df['Assumed_G_Median'] = MedianIndex_df['Assumed_G_Median']\n",
    "Index_df['EV_Sales_1y_Fwd_Median'] = MedianIndex_df['EV_Sales_1y_Fwd_Median']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Median'] = MedianIndex_df['EV_EBITDA_1y_Fwd_Median']\n",
    "Index_df['PE_TTM_Median'] = MedianIndex_df['PE_TTM_Median']\n",
    "Index_df['PE_1y_Fwd_Median'] = MedianIndex_df['PE_1y_Fwd_Median']\n",
    "Index_df['PE_2y_Fwd_Median'] = MedianIndex_df['PE_2y_Fwd_Median']\n",
    "Index_df['PB_TTM_Median'] = MedianIndex_df['PB_TTM_Median']\n",
    "Index_df['PB_1y_Fwd_Median'] = MedianIndex_df['PB_1y_Fwd_Median']\n",
    "Index_df['PB_2y_Fwd_Median'] = MedianIndex_df['PB_2y_Fwd_Median']\n",
    "Index_df['DY_TTM_Median'] = MedianIndex_df['DY_TTM_Median']\n",
    "Index_df['DY_1y_Fwd_Median'] = MedianIndex_df['DY_1y_Fwd_Median']\n",
    "Index_df['DY_2y_Fwd_Median'] = MedianIndex_df['DY_2y_Fwd_Median']\n",
    "Index_df['NOSH_Chg_LTM_Median'] = MedianIndex_df['NOSH_Chg_LTM_Median']\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#Index_df.tail()\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_index_file_name \n",
    "Index_df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94420f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LONG / SHORT RETURNS BY VARIABLE ###\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                  'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                  'NTM_EBITDA_Margin_3mChg_SOM','Sales_EV_1y_Fwd_SOM',\n",
    "                  'EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "LS_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    df['TR'] = pd.to_numeric(df['TR'], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean TR where target_column is above the median\n",
    "        long_mean_tr = group[group[target_column] > median_value]['TR'].mean()\n",
    "        \n",
    "        # Short: mean TR where target_column is below the median\n",
    "        short_mean_tr = group[group[target_column] < median_value]['TR'].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'Long_{target_column}': long_mean_tr,  # Dynamically naming the column\n",
    "            f'Short_{target_column}': short_mean_tr  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'LS_{target_column}'] = (1 + target_df[f'Long_{target_column}']) / (1 + target_df[f'Short_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    LS_results_df = pd.merge(LS_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(LS_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_LS_file_name \n",
    "LS_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ff0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALUATION DISPERSION BY VARIABLE ###\n",
    "\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['NTM_RevGrowth', '2y_RevGrowth',\n",
    "                  'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                  'RoE_1y_Fwd','RoE_2y_Fwd',\n",
    "                  'CoE','Assumed_G',\n",
    "                  'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd','EY_1y_Fwd','EY_2y_Fwd',]\n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "dispersion_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean of target_column where target_column is above the median\n",
    "        long_mean_target = group[group[target_column] > median_value][target_column].mean()\n",
    "        \n",
    "        # Short: mean of target_column where target_column is below the median\n",
    "        short_mean_target = group[group[target_column] < median_value][target_column].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'above_{target_column}': long_mean_target,  # Dynamically naming the column\n",
    "            f'below_{target_column}': short_mean_target  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'spread_{target_column}'] = (1 + target_df[f'above_{target_column}']) / (1 + target_df[f'below_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    dispersion_results_df = pd.merge(dispersion_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(dispersion_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_dispersion_file_name \n",
    "dispersion_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine stock by stock data for a single month\n",
    "examine_data = df[(df['Date'] >= '2024-09-30') & (df['Date'] <= '2024-09-30')]\n",
    "\n",
    "# Export to xlsx\n",
    "full_export_path = export_path + export_examine_CSV_file_name\n",
    "examine_data.to_excel(full_export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
