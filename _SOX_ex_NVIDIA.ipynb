{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a1f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mkt_Cap</th>\n",
       "      <th>Mkt_Cap_SOM</th>\n",
       "      <th>TR</th>\n",
       "      <th>NTM_RevGrowth_EOM</th>\n",
       "      <th>2y_RevGrowth_EOM</th>\n",
       "      <th>NTM_RevGrowth_3mChg_SOM</th>\n",
       "      <th>NTM_Rev_3mChg_SOM</th>\n",
       "      <th>NTM_EBITDA_Margin_EOM</th>\n",
       "      <th>...</th>\n",
       "      <th>PB_TTM</th>\n",
       "      <th>BY_1y_Fwd</th>\n",
       "      <th>PB_1y_Fwd</th>\n",
       "      <th>BY_2y_Fwd</th>\n",
       "      <th>PB_2y_Fwd</th>\n",
       "      <th>DY_TTM</th>\n",
       "      <th>DY_1y_Fwd</th>\n",
       "      <th>DY_2y_Fwd</th>\n",
       "      <th>NOSH_Chg_LTM</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0214411003</td>\n",
       "      <td>11136.04</td>\n",
       "      <td>9957.50</td>\n",
       "      <td>0.129999</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>-0.014959</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.322954</td>\n",
       "      <td>...</td>\n",
       "      <td>3.393234</td>\n",
       "      <td>0.304581</td>\n",
       "      <td>3.283197</td>\n",
       "      <td>0.330576</td>\n",
       "      <td>3.025027</td>\n",
       "      <td>0.018049</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>42362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0326541051</td>\n",
       "      <td>18242.66</td>\n",
       "      <td>16241.66</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>0.119085</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.388043</td>\n",
       "      <td>...</td>\n",
       "      <td>3.806242</td>\n",
       "      <td>0.278833</td>\n",
       "      <td>3.586372</td>\n",
       "      <td>0.313726</td>\n",
       "      <td>3.187492</td>\n",
       "      <td>0.024821</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>45566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0382221051</td>\n",
       "      <td>30778.86</td>\n",
       "      <td>27898.39</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>-0.003712</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.250525</td>\n",
       "      <td>...</td>\n",
       "      <td>3.751123</td>\n",
       "      <td>0.296413</td>\n",
       "      <td>3.373669</td>\n",
       "      <td>0.343324</td>\n",
       "      <td>2.912698</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0420681068</td>\n",
       "      <td>25157.13</td>\n",
       "      <td>21924.84</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.136330</td>\n",
       "      <td>-0.026942</td>\n",
       "      <td>-0.005572</td>\n",
       "      <td>0.556584</td>\n",
       "      <td>...</td>\n",
       "      <td>11.756816</td>\n",
       "      <td>0.037217</td>\n",
       "      <td>26.869347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>USN070592100</td>\n",
       "      <td>47188.38</td>\n",
       "      <td>45533.27</td>\n",
       "      <td>0.036564</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>-0.016665</td>\n",
       "      <td>-0.040214</td>\n",
       "      <td>0.294703</td>\n",
       "      <td>...</td>\n",
       "      <td>5.357747</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>4.651553</td>\n",
       "      <td>0.212820</td>\n",
       "      <td>4.698814</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>45566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          ISIN   Mkt_Cap  Mkt_Cap_SOM        TR  \\\n",
       "0 2015-02-28  US0214411003  11136.04      9957.50  0.129999   \n",
       "1 2015-02-28  US0326541051  18242.66     16241.66  0.131119   \n",
       "2 2015-02-28  US0382221051  30778.86     27898.39  0.101307   \n",
       "3 2015-02-28  US0420681068  25157.13     21924.84  0.141548   \n",
       "4 2015-02-28  USN070592100  47188.38     45533.27  0.036564   \n",
       "\n",
       "   NTM_RevGrowth_EOM  2y_RevGrowth_EOM  NTM_RevGrowth_3mChg_SOM  \\\n",
       "0           0.035620          0.051850                -0.014959   \n",
       "1           0.119085          0.087081                -0.026266   \n",
       "2           0.081776          0.066467                -0.003712   \n",
       "3           0.136868          0.136330                -0.026942   \n",
       "4           0.048862          0.076889                -0.016665   \n",
       "\n",
       "   NTM_Rev_3mChg_SOM  NTM_EBITDA_Margin_EOM  ...     PB_TTM  BY_1y_Fwd  \\\n",
       "0           0.010868               0.322954  ...   3.393234   0.304581   \n",
       "1           0.011688               0.388043  ...   3.806242   0.278833   \n",
       "2           0.020253               0.250525  ...   3.751123   0.296413   \n",
       "3          -0.005572               0.556584  ...  11.756816   0.037217   \n",
       "4          -0.040214               0.294703  ...   5.357747   0.214982   \n",
       "\n",
       "   PB_1y_Fwd  BY_2y_Fwd  PB_2y_Fwd    DY_TTM  DY_1y_Fwd  DY_2y_Fwd  \\\n",
       "0   3.283197   0.330576   3.025027  0.018049   0.019270   0.019640   \n",
       "1   3.586372   0.313726   3.187492  0.024821   0.025887   0.028341   \n",
       "2   3.373669   0.343324   2.912698  0.016088   0.016367   0.016367   \n",
       "3  26.869347        NaN        NaN  0.006452   0.008330   0.010847   \n",
       "4   4.651553   0.212820   4.698814  0.007476   0.008542   0.010076   \n",
       "\n",
       "   NOSH_Chg_LTM   TIME  \n",
       "0      0.052663  42362  \n",
       "1      0.002891  45566  \n",
       "2      0.000000  45566  \n",
       "3      0.000000  42615  \n",
       "4      0.019239  45566  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## Define file path depending on which index to examine\n",
    "\n",
    "## SOX\n",
    "index_file_path = \"H:/Tech Hardware Shared/$Mike/Quant/SOX_exNVIDIA_Constit.csv\"\n",
    "csv_directory = \"H:/Tech Hardware Shared/$Mike/Quant/CSV_files\"\n",
    "export_path = \"H:/Tech Hardware Shared/$Mike/Quant/Python_Outputs/\"\n",
    "export_audit_file_name = 'SOX_audit_exNVIDIA.xlsx'\n",
    "export_index_file_name = 'SOX_Index_Avgs_exNVIDIA.xlsx'\n",
    "export_LS_file_name = 'SOX_LS_exNVIDIA.xlsx'\n",
    "export_dispersion_file_name = 'SOX_dispersion_exNVIDIA.xlsx'\n",
    "export_examine_CSV_file_name = 'SOX_indiv_CSV_exNVIDIA.xlsx'\n",
    "\n",
    "##### CREATING DATABASE DATAFRAME ######\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(index_file_path, header=0)\n",
    "# Convert the column names to datetime with the given format\n",
    "df.columns = pd.to_datetime(df.columns, format='%d-%b-%y')\n",
    "\n",
    "# Melt the DataFrame to reshape it\n",
    "df = pd.melt(df, id_vars=[], var_name='Date', value_name='ISIN')\n",
    "df['Date'] = df['Date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# Use a placeholder for NaN values in the 'ISIN' column \n",
    "df['ISIN'].fillna('placeholder', inplace=True)\n",
    "\n",
    "# Create a list to store each ISIN's data\n",
    "all_isin_data = []\n",
    "\n",
    "# Iterate through each ISIN in the 'ISIN' column \n",
    "for isin in df['ISIN'].unique():\n",
    "    # Skip if the ISIN is 'placeholder'\n",
    "    if isin != 'placeholder':\n",
    "        # Construct the file path for the CSV file\n",
    "        index_file_path = os.path.join(csv_directory, f'{isin}.csv')\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(index_file_path):        \n",
    "            # Read the CSV file\n",
    "            isin_data = pd.read_csv(index_file_path, header=0)  # Assuming header is in row 2 and 'Date' is the label\n",
    "            isin_data['Date'] = pd.to_datetime(isin_data['Date'], unit='D', origin='1899-12-30')\n",
    "            isin_data['Date'] = isin_data['Date'] + pd.offsets.MonthEnd(0)\n",
    "            isin_data['ISIN'] = isin\n",
    "            # Convert all data columns to numeric\n",
    "                                  \n",
    "            numeric_columns = ['Mkt_Cap','TR', 'PCH',\n",
    "                               'NTM_RevGrowth','2y_RevGrowth',\n",
    "                               'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                               'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                               'CoE', 'Assumed_G', \n",
    "                               'Sales_EV_1y_Fwd', 'EV_Sales_1y_Fwd', 'EBITDA_EV_1y_Fwd','EV_EBITDA_1y_Fwd',\n",
    "                               'EY_TTM','PE_TTM', 'EY_1y_Fwd','PE_1y_Fwd','EY_2y_Fwd','PE_2y_Fwd',\n",
    "                               'BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd',\n",
    "                               'DY_TTM','DY_1y_Fwd','DY_2y_Fwd',\n",
    "                               'NOSH_Chg_LTM',\n",
    "                               'TIME',\n",
    "                               'Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                               'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM',\n",
    "                               'NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                               'NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                               'Sales_EV_1y_Fwd_SOM','EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "            isin_data[numeric_columns] = isin_data[numeric_columns].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            # nix out negative BVPS data & other floors / ceilings\n",
    "            neg_cols = ['BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd','CoE']\n",
    "            for col in neg_cols:\n",
    "                isin_data[col] = np.where(isin_data[col] < 0, np.nan, isin_data[col])\n",
    "            \n",
    "            upper_bound = 0.5 # Max CoE = 50%\n",
    "            isin_data['CoE'] = isin_data['CoE'].clip(upper=upper_bound)\n",
    "                                   \n",
    "            lower_bound = -0.02 # Max multiple = -50x\n",
    "            upper_bound = 1 # Min multiple = 1x\n",
    "            isin_data['Sales_EV_1y_Fwd'] = isin_data['Sales_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EBITDA_EV_1y_Fwd'] = isin_data['EBITDA_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_TTM'] = isin_data['EY_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_1y_Fwd'] = isin_data['EY_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_2y_Fwd'] = isin_data['EY_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            \n",
    "            lower_bound = -0.5\n",
    "            upper_bound = 1.5\n",
    "            isin_data['RoE_TTM'] = isin_data['RoE_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_1y_Fwd'] = isin_data['RoE_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_2y_Fwd'] = isin_data['RoE_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "                                        \n",
    "            # Append the data to the list\n",
    "            all_isin_data.append(isin_data)\n",
    "\n",
    "# Concatenate all ISIN data into a single DataFrame\n",
    "isin_final_df = pd.concat(all_isin_data, ignore_index=True)\n",
    "\n",
    "# Merge the additional columns into the melted DataFrame using 'Date' and 'ISIN' as the keys \n",
    "df = pd.merge(df, isin_final_df, on=['Date','ISIN'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "#full_export_path = export_path + export_audit_file_name\n",
    "#df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE DATAFRAME OF EQUAL WEIGHTED AND MARKET CAP WEIGHTED AVERAGE RATIOS ####\n",
    "\n",
    "\n",
    "### Equal Weight Calculation\n",
    "EqualWeightIndex_df = df.groupby('Date')[['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].mean().reset_index()\n",
    "\n",
    "EqualWeightIndex_df.columns = [f'{col}_Eq_Wgt' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in EqualWeightIndex_df.columns]\n",
    "\n",
    "EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['Sales_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EBITDA_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_2y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_2y_Fwd_Eq_Wgt']\n",
    "\n",
    "\n",
    "### Median Weight Calculation\n",
    "MedianIndex_df = df.groupby('Date')[['TR',\n",
    "                                     'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                     'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                     'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                     'CoE', 'Assumed_G',\n",
    "                                     'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                     'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                     'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                     'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].median().reset_index()\n",
    "\n",
    "MedianIndex_df.columns = [f'{col}_Median' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in MedianIndex_df.columns]\n",
    "\n",
    "MedianIndex_df['EV_Sales_1y_Fwd_Median'] = 1/MedianIndex_df['Sales_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['EV_EBITDA_1y_Fwd_Median'] = 1/MedianIndex_df['EBITDA_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_TTM_Median'] = 1/MedianIndex_df['EY_TTM_Median']\n",
    "MedianIndex_df['PE_1y_Fwd_Median'] = 1/MedianIndex_df['EY_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_2y_Fwd_Median'] = 1/MedianIndex_df['EY_2y_Fwd_Median']\n",
    "MedianIndex_df['PB_TTM_Median'] = 1/MedianIndex_df['BY_TTM_Median']\n",
    "MedianIndex_df['PB_1y_Fwd_Median'] = 1/MedianIndex_df['BY_1y_Fwd_Median']\n",
    "MedianIndex_df['PB_2y_Fwd_Median'] = 1/MedianIndex_df['BY_2y_Fwd_Median']\n",
    "\n",
    "### MKT CAP WEIGHTED CALCULATION\n",
    "\n",
    "# Step 1: Create a function for weighted average calculation\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    valid_entries = ~df[value_col].isna()\n",
    "    weights = df.loc[valid_entries, weight_col]\n",
    "    values = df.loc[valid_entries, value_col]\n",
    "    if weights.sum() == 0:\n",
    "        # Handle the case where denominator is zero\n",
    "        return 0\n",
    "    else:\n",
    "        weighted_avg = (weights * values).sum() / weights.sum()\n",
    "        return weighted_avg\n",
    "\n",
    "# Step 2: Create a function to calculate the market cap weighted averages\n",
    "def calculate_weighted_averages(group):\n",
    "    weighted_TR = weighted_average(group, 'TR', 'Mkt_Cap_SOM')\n",
    "    weighted_NTM_RevGrowth = weighted_average(group, 'NTM_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_2y_RevGrowth = weighted_average(group, '2y_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_NTM_EBITDA_Margin = weighted_average(group, 'NTM_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_2y_EBITDA_Margin = weighted_average(group, '2y_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_RoE_TTM = weighted_average(group, 'RoE_TTM', 'Mkt_Cap')\n",
    "    weighted_RoE_1y_Fwd = weighted_average(group, 'RoE_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_RoE_2y_Fwd = weighted_average(group, 'RoE_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_CoE = weighted_average(group, 'CoE', 'Mkt_Cap')\n",
    "    weighted_Assumed_G = weighted_average(group, 'Assumed_G', 'Mkt_Cap')\n",
    "    weighted_Sales_EV_1y_Fwd = weighted_average(group, 'Sales_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EBITDA_EV_1y_Fwd = weighted_average(group, 'EBITDA_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_TTM = weighted_average(group, 'EY_TTM', 'Mkt_Cap')\n",
    "    weighted_EY_1y_Fwd = weighted_average(group, 'EY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_2y_Fwd = weighted_average(group, 'EY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_BY_TTM = weighted_average(group, 'BY_TTM', 'Mkt_Cap')\n",
    "    weighted_BY_1y_Fwd = weighted_average(group, 'BY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_BY_2y_Fwd = weighted_average(group, 'BY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_DY_TTM = weighted_average(group, 'DY_TTM', 'Mkt_Cap')\n",
    "    weighted_DY_1y_Fwd = weighted_average(group, 'DY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_DY_2y_Fwd = weighted_average(group, 'DY_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_NOSH_Chg_LTM = weighted_average(group, 'NOSH_Chg_LTM', 'Mkt_Cap')\n",
    "    \n",
    "    \n",
    "    return pd.Series({\n",
    "        'TR_MV_Wgt': weighted_TR,\n",
    "        'NTM_RevGrowth_MV_Wgt': weighted_NTM_RevGrowth,\n",
    "        '2y_RevGrowth_MV_Wgt': weighted_2y_RevGrowth,\n",
    "        'NTM_EBITDA_Margin_MV_Wgt': weighted_NTM_EBITDA_Margin,\n",
    "        '2y_EBITDA_Margin_MV_Wgt': weighted_2y_EBITDA_Margin,\n",
    "        'RoE_TTM_MV_Wgt': weighted_RoE_TTM,\n",
    "        'RoE_1y_Fwd_MV_Wgt': weighted_RoE_1y_Fwd,\n",
    "        'RoE_2y_Fwd_MV_Wgt': weighted_RoE_2y_Fwd,\n",
    "        'CoE_MV_Wgt': weighted_CoE,\n",
    "        'Assumed_G_MV_Wgt': weighted_Assumed_G,\n",
    "        'EV_Sales_1y_Fwd_MV_Wgt': weighted_Sales_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'EV_EBITDA_1y_Fwd_MV_Wgt': weighted_EBITDA_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_TTM_MV_Wgt': weighted_EY_TTM, # execution of reciprocal below\n",
    "        'PE_1y_Fwd_MV_Wgt': weighted_EY_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_2y_Fwd_MV_Wgt': weighted_EY_2y_Fwd, # execution of reciprocal below\n",
    "        'PB_TTM_MV_Wgt': weighted_BY_TTM, # execution of reciprocal below\n",
    "        'PB_1y_Fwd_MV_Wgt': weighted_BY_1y_Fwd, # execution of reciprocal below\n",
    "        'PB_2y_Fwd_MV_Wgt': weighted_BY_2y_Fwd, # execution of reciprocal below\n",
    "        'DY_TTM_MV_Wgt': weighted_DY_TTM,\n",
    "        'DY_1y_Fwd_MV_Wgt': weighted_DY_1y_Fwd,\n",
    "        'DY_2y_Fwd_MV_Wgt': weighted_DY_2y_Fwd,\n",
    "        'NOSH_Chg_LTM_MV_Wgt': weighted_NOSH_Chg_LTM\n",
    "    })\n",
    "\n",
    "# Step 3: Apply the calculation to your DataFrame\n",
    "Index_df = df.groupby('Date').apply(calculate_weighted_averages).reset_index()\n",
    "Index_df['EV_Sales_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_Sales_1y_Fwd_MV_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_EBITDA_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_TTM_MV_Wgt'] = 1/Index_df['PE_TTM_MV_Wgt']\n",
    "Index_df['PE_1y_Fwd_MV_Wgt'] = 1/Index_df['PE_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_2y_Fwd_MV_Wgt'] = 1/Index_df['PE_2y_Fwd_MV_Wgt']\n",
    "Index_df['PB_TTM_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_1y_Fwd_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_2y_Fwd_MV_Wgt'] = 1/Index_df['PB_2y_Fwd_MV_Wgt']\n",
    "\n",
    "# Step 4: Add in the equal weighted calculations from above into the Index dataframe\n",
    "Index_df['TR_Eq_Wgt'] = EqualWeightIndex_df['TR_Eq_Wgt']\n",
    "Index_df['NTM_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['NTM_RevGrowth_Eq_Wgt']\n",
    "Index_df['2y_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['2y_RevGrowth_Eq_Wgt']\n",
    "Index_df['NTM_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['NTM_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['2y_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['2y_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['RoE_TTM_Eq_Wgt'] = EqualWeightIndex_df['RoE_TTM_Eq_Wgt']\n",
    "Index_df['RoE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['RoE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['CoE_Eq_Wgt'] = EqualWeightIndex_df['CoE_Eq_Wgt']\n",
    "Index_df['Assumed_G_Eq_Wgt'] = EqualWeightIndex_df['Assumed_G_Eq_Wgt']\n",
    "Index_df['EV_Sales_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_TTM_Eq_Wgt'] = EqualWeightIndex_df['PE_TTM_Eq_Wgt']\n",
    "Index_df['PE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_TTM_Eq_Wgt'] = EqualWeightIndex_df['PB_TTM_Eq_Wgt']\n",
    "Index_df['PB_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_TTM_Eq_Wgt'] = EqualWeightIndex_df['DY_TTM_Eq_Wgt']\n",
    "Index_df['DY_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_1y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_2y_Fwd_Eq_Wgt']\n",
    "Index_df['NOSH_Chg_LTM_Eq_Wgt'] = EqualWeightIndex_df['NOSH_Chg_LTM_Eq_Wgt']\n",
    "\n",
    "# Step 5: Add in the median calculations from above into the Index dataframe\n",
    "Index_df['TR_Median'] = MedianIndex_df['TR_Median']\n",
    "Index_df['NTM_RevGrowth_Median'] = MedianIndex_df['NTM_RevGrowth_Median']\n",
    "Index_df['2y_RevGrowth_Median'] = MedianIndex_df['2y_RevGrowth_Median']\n",
    "Index_df['NTM_EBITDA_Margin_Median'] = MedianIndex_df['NTM_EBITDA_Margin_Median']\n",
    "Index_df['2y_EBITDA_Margin_Median'] = MedianIndex_df['2y_EBITDA_Margin_Median']\n",
    "Index_df['RoE_TTM_Median'] = MedianIndex_df['RoE_TTM_Median']\n",
    "Index_df['RoE_1y_Fwd_Median'] = MedianIndex_df['RoE_1y_Fwd_Median']\n",
    "Index_df['RoE_2y_Fwd_Median'] = MedianIndex_df['RoE_2y_Fwd_Median']\n",
    "Index_df['CoE_Median'] = MedianIndex_df['CoE_Median']\n",
    "Index_df['Assumed_G_Median'] = MedianIndex_df['Assumed_G_Median']\n",
    "Index_df['EV_Sales_1y_Fwd_Median'] = MedianIndex_df['EV_Sales_1y_Fwd_Median']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Median'] = MedianIndex_df['EV_EBITDA_1y_Fwd_Median']\n",
    "Index_df['PE_TTM_Median'] = MedianIndex_df['PE_TTM_Median']\n",
    "Index_df['PE_1y_Fwd_Median'] = MedianIndex_df['PE_1y_Fwd_Median']\n",
    "Index_df['PE_2y_Fwd_Median'] = MedianIndex_df['PE_2y_Fwd_Median']\n",
    "Index_df['PB_TTM_Median'] = MedianIndex_df['PB_TTM_Median']\n",
    "Index_df['PB_1y_Fwd_Median'] = MedianIndex_df['PB_1y_Fwd_Median']\n",
    "Index_df['PB_2y_Fwd_Median'] = MedianIndex_df['PB_2y_Fwd_Median']\n",
    "Index_df['DY_TTM_Median'] = MedianIndex_df['DY_TTM_Median']\n",
    "Index_df['DY_1y_Fwd_Median'] = MedianIndex_df['DY_1y_Fwd_Median']\n",
    "Index_df['DY_2y_Fwd_Median'] = MedianIndex_df['DY_2y_Fwd_Median']\n",
    "Index_df['NOSH_Chg_LTM_Median'] = MedianIndex_df['NOSH_Chg_LTM_Median']\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#Index_df.tail()\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_index_file_name \n",
    "Index_df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94420f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LONG / SHORT RETURNS BY VARIABLE ###\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                  'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                  'NTM_EBITDA_Margin_3mChg_SOM','Sales_EV_1y_Fwd_SOM',\n",
    "                  'EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "LS_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    df['TR'] = pd.to_numeric(df['TR'], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean TR where target_column is above the median\n",
    "        long_mean_tr = group[group[target_column] > median_value]['TR'].mean()\n",
    "        \n",
    "        # Short: mean TR where target_column is below the median\n",
    "        short_mean_tr = group[group[target_column] < median_value]['TR'].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'Long_{target_column}': long_mean_tr,  # Dynamically naming the column\n",
    "            f'Short_{target_column}': short_mean_tr  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'LS_{target_column}'] = (1 + target_df[f'Long_{target_column}']) / (1 + target_df[f'Short_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    LS_results_df = pd.merge(LS_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(LS_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_LS_file_name \n",
    "LS_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ff0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALUATION DISPERSION BY VARIABLE ###\n",
    "\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['NTM_RevGrowth', '2y_RevGrowth',\n",
    "                  'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                  'RoE_1y_Fwd','RoE_2y_Fwd',\n",
    "                  'CoE','Assumed_G',\n",
    "                  'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd','EY_1y_Fwd','EY_2y_Fwd',]\n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "dispersion_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean of target_column where target_column is above the median\n",
    "        long_mean_target = group[group[target_column] > median_value][target_column].mean()\n",
    "        \n",
    "        # Short: mean of target_column where target_column is below the median\n",
    "        short_mean_target = group[group[target_column] < median_value][target_column].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'above_{target_column}': long_mean_target,  # Dynamically naming the column\n",
    "            f'below_{target_column}': short_mean_target  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'spread_{target_column}'] = (1 + target_df[f'above_{target_column}']) / (1 + target_df[f'below_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    dispersion_results_df = pd.merge(dispersion_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(dispersion_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_dispersion_file_name \n",
    "dispersion_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine stock by stock data for a single month\n",
    "examine_data = df[(df['Date'] >= '2024-09-30') & (df['Date'] <= '2024-09-30')]\n",
    "\n",
    "# Export to xlsx\n",
    "full_export_path = export_path + export_examine_CSV_file_name\n",
    "examine_data.to_excel(full_export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
