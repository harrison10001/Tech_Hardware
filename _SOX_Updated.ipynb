{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a1f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mkt_Cap</th>\n",
       "      <th>EV_NTM</th>\n",
       "      <th>RI</th>\n",
       "      <th>P</th>\n",
       "      <th>NOSH</th>\n",
       "      <th>Reccon</th>\n",
       "      <th>Rev_LTM</th>\n",
       "      <th>Rev_NTM</th>\n",
       "      <th>...</th>\n",
       "      <th>NTM_EBITDA_Margin_3mChg_SOM</th>\n",
       "      <th>Sales_EV_NTM_SOM</th>\n",
       "      <th>EBITDA_EV_NTM_SOM</th>\n",
       "      <th>EY_NTM_SOM</th>\n",
       "      <th>EY_2yFwd_SOM</th>\n",
       "      <th>BY_NTM_SOM</th>\n",
       "      <th>CoE_SOM</th>\n",
       "      <th>Implied_G_SOM</th>\n",
       "      <th>Rev_MTUM_LTM_SOM</th>\n",
       "      <th>EPS_MTUM_LTM_SOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>US7475251036</td>\n",
       "      <td>181325.90</td>\n",
       "      <td>190254.10</td>\n",
       "      <td>46468.25</td>\n",
       "      <td>162.77</td>\n",
       "      <td>1114.000737</td>\n",
       "      <td>2.24</td>\n",
       "      <td>38919.570</td>\n",
       "      <td>42507.465730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004429</td>\n",
       "      <td>0.222417</td>\n",
       "      <td>0.084392</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.156601</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.011280</td>\n",
       "      <td>-0.015166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>US83088M1027</td>\n",
       "      <td>13987.96</td>\n",
       "      <td>17509.50</td>\n",
       "      <td>27731.71</td>\n",
       "      <td>87.58</td>\n",
       "      <td>159.716374</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4196.293</td>\n",
       "      <td>4257.032351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015560</td>\n",
       "      <td>0.234227</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.065101</td>\n",
       "      <td>0.079478</td>\n",
       "      <td>0.396578</td>\n",
       "      <td>0.100554</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>-0.062322</td>\n",
       "      <td>-0.224335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>US8740391003</td>\n",
       "      <td>988207.50</td>\n",
       "      <td>377883.30</td>\n",
       "      <td>6183.11</td>\n",
       "      <td>190.54</td>\n",
       "      <td>5186.351947</td>\n",
       "      <td>1.64</td>\n",
       "      <td>86075.440</td>\n",
       "      <td>108545.352200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.270663</td>\n",
       "      <td>0.185315</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>0.054510</td>\n",
       "      <td>0.161167</td>\n",
       "      <td>0.083723</td>\n",
       "      <td>0.051627</td>\n",
       "      <td>0.157311</td>\n",
       "      <td>0.136863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>US8807701029</td>\n",
       "      <td>17297.51</td>\n",
       "      <td>19399.39</td>\n",
       "      <td>9792.07</td>\n",
       "      <td>106.21</td>\n",
       "      <td>162.861407</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2784.865</td>\n",
       "      <td>3257.768970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.041760</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.143802</td>\n",
       "      <td>0.080927</td>\n",
       "      <td>0.055426</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>-0.088316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>US8825081040</td>\n",
       "      <td>185325.90</td>\n",
       "      <td>188827.70</td>\n",
       "      <td>24883.04</td>\n",
       "      <td>203.16</td>\n",
       "      <td>912.216480</td>\n",
       "      <td>2.82</td>\n",
       "      <td>15842.160</td>\n",
       "      <td>16922.930270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.092802</td>\n",
       "      <td>0.044503</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.099937</td>\n",
       "      <td>0.075114</td>\n",
       "      <td>0.061829</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.022074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          ISIN    Mkt_Cap     EV_NTM        RI       P  \\\n",
       "3387 2024-10-31  US7475251036  181325.90  190254.10  46468.25  162.77   \n",
       "3388 2024-10-31  US83088M1027   13987.96   17509.50  27731.71   87.58   \n",
       "3389 2024-10-31  US8740391003  988207.50  377883.30   6183.11  190.54   \n",
       "3390 2024-10-31  US8807701029   17297.51   19399.39   9792.07  106.21   \n",
       "3391 2024-10-31  US8825081040  185325.90  188827.70  24883.04  203.16   \n",
       "\n",
       "             NOSH  Reccon    Rev_LTM        Rev_NTM  ...  \\\n",
       "3387  1114.000737    2.24  38919.570   42507.465730  ...   \n",
       "3388   159.716374    2.80   4196.293    4257.032351  ...   \n",
       "3389  5186.351947    1.64  86075.440  108545.352200  ...   \n",
       "3390   162.861407    2.36   2784.865    3257.768970  ...   \n",
       "3391   912.216480    2.82  15842.160   16922.930270  ...   \n",
       "\n",
       "      NTM_EBITDA_Margin_3mChg_SOM  Sales_EV_NTM_SOM  EBITDA_EV_NTM_SOM  \\\n",
       "3387                    -0.004429          0.222417           0.084392   \n",
       "3388                    -0.015560          0.234227           0.075223   \n",
       "3389                     0.008211          0.270663           0.185315   \n",
       "3390                     0.006052          0.149770           0.041760   \n",
       "3391                    -0.000196          0.092802           0.044503   \n",
       "\n",
       "      EY_NTM_SOM  EY_2yFwd_SOM  BY_NTM_SOM   CoE_SOM  Implied_G_SOM  \\\n",
       "3387    0.065451      0.071214    0.156601  0.095870       0.035916   \n",
       "3388    0.065101      0.079478    0.396578  0.100554       0.020993   \n",
       "3389    0.045152      0.054510    0.161167  0.083723       0.051627   \n",
       "3390    0.031820      0.044437    0.143802  0.080927       0.055426   \n",
       "3391    0.029385      0.035797    0.099937  0.075114       0.061829   \n",
       "\n",
       "      Rev_MTUM_LTM_SOM  EPS_MTUM_LTM_SOM  \n",
       "3387          0.011280         -0.015166  \n",
       "3388         -0.062322         -0.224335  \n",
       "3389          0.157311          0.136863  \n",
       "3390          0.004469         -0.088316  \n",
       "3391          0.017003          0.022074  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## Define file path depending on which index to examine\n",
    "\n",
    "## SOX\n",
    "index_file_path = \"H:/Tech Hardware Shared/$Mike/Quant/SOX_Constit.csv\"\n",
    "csv_directory = \"H:/Tech Hardware Shared/$Mike/Quant/CSV_files/Updated\"\n",
    "export_path = \"H:/Tech Hardware Shared/$Mike/Quant/Python_Outputs/Updated/\"\n",
    "export_audit_file_name = 'SOX_audit_updated.xlsx'\n",
    "export_index_file_name = 'SOX_Index_Avg_Updateds.xlsx'\n",
    "export_LS_file_name = 'SOX_LS_Updated.xlsx'\n",
    "export_dispersion_file_name = 'SOX_dispersion_Updated.xlsx'\n",
    "export_examine_CSV_file_name = 'SOX_indiv_CSV_Updated.xlsx'\n",
    "\n",
    "##### CREATING DATABASE DATAFRAME ######\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(index_file_path, header=0)\n",
    "# Convert the column names to datetime with the given format\n",
    "df.columns = pd.to_datetime(df.columns, format='%d-%b-%y')\n",
    "\n",
    "# Melt the DataFrame to reshape it\n",
    "df = pd.melt(df, id_vars=[], var_name='Date', value_name='ISIN')\n",
    "df['Date'] = df['Date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# Use a placeholder for NaN values in the 'ISIN' column \n",
    "df['ISIN'].fillna('placeholder', inplace=True)\n",
    "\n",
    "# Create a list to store each ISIN's data\n",
    "all_isin_data = []\n",
    "\n",
    "# Iterate through each ISIN in the 'ISIN' column \n",
    "for isin in df['ISIN'].unique():\n",
    "    # Skip if the ISIN is 'placeholder'\n",
    "    if isin != 'placeholder':\n",
    "        # Construct the file path for the CSV file\n",
    "        index_file_path = os.path.join(csv_directory, f'{isin}.csv')\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(index_file_path):        \n",
    "            # Read the CSV file\n",
    "            isin_data = pd.read_csv(index_file_path, header=0)  # Assuming header is in row 2 and 'Date' is the label\n",
    "            isin_data['Date'] = pd.to_datetime(isin_data['Date'], unit='D', origin='1899-12-30')\n",
    "            isin_data['Date'] = isin_data['Date'] + pd.offsets.MonthEnd(0)\n",
    "            isin_data['ISIN'] = isin\n",
    "            \n",
    "            # Convert all data columns to numeric                   \n",
    "            numeric_columns = ['Mkt_Cap','EV_NTM','RI','P','NOSH','Reccon',\n",
    "                               'Rev_LTM','Rev_NTM','Rev_2yFwd',\n",
    "                               'EBITDA_LTM','EBITDA_NTM','EBITDA_2yFwd',\n",
    "                               'EPS_LTM','EPS_NTM','EPS_2yFwd',\n",
    "                               'BPS_LTM','BPS_NTM','BPS_2yFwd',\n",
    "                               'DPS_LTM','DPS_NTM','DPS_2yFwd',\n",
    "                               'CFPS_LTM','CF_LTM_DS','CFPS_NTM',\n",
    "                               'Assets_LTM',\n",
    "                               'NetDebt_LTM','NetDebt_LTM_DS','NetDebt_NTM']            \n",
    "            isin_data[numeric_columns] = isin_data[numeric_columns].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Data cleanse\n",
    "            isin_data['NetDebt_LTM_Best'] = np.where(pd.notnull(isin_data['NetDebt_LTM']),isin_data['NetDebt_LTM'],isin_data['NetDebt_LTM_DS'])\n",
    "            # nix out negative BVPS data\n",
    "            #neg_cols = ['BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd','CoE']\n",
    "            #for col in neg_cols:\n",
    "            #    isin_data[col] = np.where(isin_data[col] < 0, np.nan, isin_data[col]) \n",
    "            \n",
    "            isin_data['Mkt_Cap_SOM'] = isin_data['Mkt_Cap'].shift(1)\n",
    "            isin_data['TR'] = isin_data['RI'] / isin_data['RI'].shift(1) -1\n",
    "            isin_data['TR_LTM'] = isin_data['RI'] / isin_data['RI'].shift(12) -1\n",
    "            isin_data['TR_L6M'] = isin_data['RI'] / isin_data['RI'].shift(6) -1\n",
    "            isin_data['TR_L3M'] = isin_data['RI'] / isin_data['RI'].shift(3) -1\n",
    "            isin_data['PCH'] = isin_data['P'] / isin_data['P'].shift(1) -1\n",
    "            isin_data['PCH_LTM'] = isin_data['P'] / isin_data['P'].shift(12) -1\n",
    "            isin_data['PCH_L6M'] = isin_data['P'] / isin_data['P'].shift(6) -1           \n",
    "            isin_data['PCH_L3M'] = isin_data['P'] / isin_data['P'].shift(3) -1           \n",
    "            isin_data['NTM_RevGrowth'] = isin_data['Rev_NTM'] / isin_data['Rev_LTM'] - 1\n",
    "            isin_data['2y_RevCAGR'] = (isin_data['Rev_2yFwd'] / isin_data['Rev_LTM'])**(1/2) - 1\n",
    "            isin_data['NTM_RevGrowth_3mChg'] = isin_data['NTM_RevGrowth'] - isin_data['NTM_RevGrowth'].shift(3)\n",
    "            isin_data['NTM_Rev_3mChg'] = isin_data['Rev_NTM'] / isin_data['Rev_NTM'].shift(3) - 1\n",
    "            isin_data['LTM_EBITDA_Margin'] = isin_data['EBITDA_LTM'] / isin_data['Rev_LTM']\n",
    "            isin_data['NTM_EBITDA_Margin'] = isin_data['EBITDA_NTM'] / isin_data['Rev_NTM']\n",
    "            isin_data['2yFwd_EBITDA_Margin'] = isin_data['EBITDA_2yFwd'] / isin_data['Rev_2yFwd']\n",
    "            isin_data['NTM_EBITDA_Margin_3mChg'] = isin_data['NTM_EBITDA_Margin'] - isin_data['NTM_EBITDA_Margin'].shift(3)\n",
    "            isin_data['RoE_LTM'] = isin_data['EPS_LTM'] / isin_data['BPS_LTM']\n",
    "            isin_data['RoE_NTM'] = isin_data['EPS_NTM'] / isin_data['BPS_NTM']\n",
    "            isin_data['RoE_2yFwd'] = isin_data['EPS_2yFwd'] / isin_data['BPS_2yFwd']\n",
    "            isin_data['Sales_EV_NTM'] = isin_data['Rev_NTM'] / isin_data['EV_NTM']\n",
    "            isin_data['EBITDA_EV_NTM'] = isin_data['EBITDA_NTM'] / isin_data['EV_NTM']\n",
    "            isin_data['EV_LTM'] = isin_data['Mkt_Cap'] + isin_data['NetDebt_LTM_Best']\n",
    "            isin_data['EY_LTM'] = isin_data['EPS_LTM'] / isin_data['P']\n",
    "            isin_data['EY_NTM'] = isin_data['EPS_NTM'] / isin_data['P']\n",
    "            isin_data['EY_2yFwd'] = isin_data['EPS_2yFwd'] / isin_data['P']\n",
    "            isin_data['BY_LTM'] = isin_data['BPS_LTM'] / isin_data['P']\n",
    "            isin_data['BY_NTM'] = isin_data['BPS_NTM'] / isin_data['P']\n",
    "            isin_data['BY_2yFwd'] = isin_data['BPS_2yFwd'] / isin_data['P']\n",
    "            isin_data['DY_LTM'] = isin_data['DPS_LTM'] / isin_data['P']\n",
    "            isin_data['DY_NTM'] = isin_data['DPS_NTM'] / isin_data['P']\n",
    "            isin_data['DY_2yFwd'] = isin_data['DPS_2yFwd'] / isin_data['P']\n",
    "            isin_data['NOSH_Chg_LTM'] = isin_data['NOSH'] / isin_data['NOSH'].shift(12) - 1\n",
    "            isin_data['CFY_LTM'] = isin_data['CFPS_LTM'] / isin_data['P']\n",
    "            isin_data['CFY_LTM_DS'] = isin_data['CF_LTM_DS'] / isin_data['Mkt_Cap']\n",
    "            isin_data['CFY_NTM'] = isin_data['CFPS_NTM'] / isin_data['P']\n",
    "            isin_data['CF_Assets'] = isin_data['CF_LTM_DS'] / isin_data['Assets_LTM']\n",
    "            isin_data['EBITDA_Assets'] = isin_data['EBITDA_LTM'] / isin_data['Assets_LTM']\n",
    "                                  \n",
    "            # CoE calculation\n",
    "                                 \n",
    "            # Define g\n",
    "            conditions = [\n",
    "                (isin_data['RoE_2yFwd'] < 0.1),\n",
    "                (isin_data['RoE_2yFwd'] >= 0.1) & (isin_data['RoE_2yFwd'] < 0.15),\n",
    "                (isin_data['RoE_2yFwd'] > 0.15)\n",
    "            ]\n",
    "            values = [0, 0.03, 0.05]\n",
    "            isin_data['Term_G'] = np.select(conditions, values)\n",
    "            \n",
    "            # Default CoE to use when no prior CoE is available\n",
    "            default_CoE = 0.085\n",
    "\n",
    "            # Initialize the CoE column with NaN values\n",
    "            isin_data['CoE'] = np.nan\n",
    "\n",
    "            # Iteratively calculate CoE\n",
    "            for i in range(len(isin_data)):\n",
    "                # Get or set CoE for current iteration\n",
    "                if i == 0 or pd.isnull(isin_data.loc[i - 1, 'CoE']):\n",
    "                    current_CoE = default_CoE  # Use default CoE for the first iteration or if prior CoE is missing\n",
    "                else:\n",
    "                    current_CoE = isin_data.loc[i - 1, 'CoE']\n",
    "\n",
    "                # Calculate temporary values needed for CoE\n",
    "                isin_data.loc[i,'Adj_RoE'] = isin_data.loc[i,'RoE_2yFwd'] / (1 + current_CoE)**2\n",
    "                isin_data.loc[i,'Adj_Price'] = (\n",
    "                    (1 - (\n",
    "                        (isin_data.loc[i,'DY_NTM'] + isin_data.loc[i,'NOSH_Chg_LTM']) / (1 + current_CoE) +\n",
    "                        (isin_data.loc[i,'DY_2yFwd'] + isin_data.loc[i,'NOSH_Chg_LTM']) / (1 + current_CoE)**2\n",
    "                    )) * isin_data.loc[i,'P']\n",
    "                )\n",
    "                isin_data.loc[i, 'Adj_PB'] = isin_data.loc[i, 'Adj_Price'] / isin_data.loc[i,'BPS_NTM']\n",
    "\n",
    "                # Calculate CoE for the current row\n",
    "                isin_data.loc[i,'CoE'] = (\n",
    "                    (isin_data.loc[i,'Adj_RoE'] - isin_data.loc[i,'Term_G']) / isin_data.loc[i,'Adj_PB']\n",
    "                ) + isin_data.loc[i,'Term_G']\n",
    "                \n",
    "            # Implied g calculation\n",
    "            isin_data['Adj_RoE'] = isin_data['RoE_2yFwd'] / (1 + default_CoE)**2\n",
    "            isin_data['Adj_Price'] = (1-((isin_data['DY_NTM'] + isin_data['NOSH_Chg_LTM']) / (1 + default_CoE) + \n",
    "                                        (isin_data['DY_2yFwd'] + isin_data['NOSH_Chg_LTM']) / (1 + default_CoE)**2))*isin_data['P']\n",
    "            isin_data['Adj_PB'] = isin_data['Adj_Price'] / isin_data['BPS_NTM']\n",
    "            \n",
    "            isin_data['Implied_G'] = (isin_data['Adj_PB']*default_CoE - isin_data['Adj_RoE']) / (isin_data['Adj_PB'] - 1)\n",
    "            \n",
    "            # Drop temporary columns after calculation\n",
    "            isin_data.drop(columns=['Adj_RoE', 'Adj_Price', 'Adj_PB'], inplace=True)\n",
    "\n",
    "            # Set boundary conditions\n",
    "            upper_bound = 0.5 # Max CoE = 50%\n",
    "            isin_data['CoE'] = isin_data['CoE'].clip(upper=upper_bound)\n",
    "                                   \n",
    "            lower_bound = -0.02 # Max multiple = -50x\n",
    "            upper_bound = 1 # Min multiple = 1x\n",
    "            isin_data['Sales_EV_NTM'] = isin_data['Sales_EV_NTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EBITDA_EV_NTM'] = isin_data['EBITDA_EV_NTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_LTM'] = isin_data['EY_LTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_NTM'] = isin_data['EY_NTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_2yFwd'] = isin_data['EY_2yFwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            \n",
    "            lower_bound = -0.5\n",
    "            upper_bound = 1.5\n",
    "            isin_data['RoE_LTM'] = isin_data['RoE_LTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_NTM'] = isin_data['RoE_NTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_2yFwd'] = isin_data['RoE_2yFwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            \n",
    "            # Revenue & EPS momentum\n",
    "                        \n",
    "            # Main function to calculate momentum metrics\n",
    "            def calculate_momentum(isin_data, base_var, initial_calc_func=None):\n",
    "                # Dictionary to store new column names for tracking\n",
    "                new_columns = {}\n",
    "                # Create a temporary DataFrame for calculations\n",
    "                temp_df = pd.DataFrame(index=isin_data.index)\n",
    "                # Perform initial calculations if an initial_calc_func is provided\n",
    "                if initial_calc_func:\n",
    "                    for i in range(1, 4):\n",
    "                        initial_calc_func(isin_data, temp_df, base_var, i)\n",
    "                # Define numerator and denominator columns based on base_var\n",
    "                numerator = f'{base_var}_NTM'\n",
    "                denominators = [f'{base_var}_1.{i}' for i in range(1, 4)]\n",
    "                # Perform the calculation for each denominator in the temp DataFrame\n",
    "                for column_name in denominators:\n",
    "                    result_column = f'F_{column_name}'\n",
    "                    temp_df[result_column] = np.where(\n",
    "                        temp_df[column_name] < 0,\n",
    "                        np.nan,\n",
    "                        isin_data[numerator] / temp_df[column_name]\n",
    "                    )\n",
    "                    new_columns[result_column] = temp_df[result_column]\n",
    "                # Calculate the momentum metric in temp_df\n",
    "                momentum_column = f'{base_var}_MTUM_LTM'\n",
    "                temp_df[momentum_column] = sum(\n",
    "                    temp_df[f'F_{base_var}_1.{i}'] ** (12 / i) - 1 for i in range(1, 4)\n",
    "                ) / 3\n",
    "                # Add only the final momentum column to isin_data\n",
    "                isin_data[momentum_column] = temp_df[momentum_column]\n",
    "\n",
    "            # Define the initial calculation function with specific calculations\n",
    "            def initial_calculation(isin_data, temp_df, base_var, index):\n",
    "                # Define the column name dynamically\n",
    "                column_name = f'{base_var}_1.{index}'\n",
    "                # Perform the calculation with the shift and weight in temp_df\n",
    "                temp_df[column_name] = (\n",
    "                    isin_data[f'{base_var}_NTM'].shift(index) * ((12 - index) / 12) +\n",
    "                    isin_data[f'{base_var}_2yFwd'].shift(index) * (index / 12)\n",
    "                )\n",
    "            # Loop through each base_var to apply the calculation for both 'EPS' and 'Rev'\n",
    "            for base_var in ['EPS', 'Rev']:\n",
    "                calculate_momentum(isin_data, base_var=base_var, initial_calc_func=initial_calculation)\n",
    "                \n",
    "            ## currently this code is resulting in intermittend NaN values in the LS calc\n",
    "            ## i think this is because of the nan error checker earlier in np.where line\n",
    "            ## how do i want to treat this?\n",
    "   \n",
    "            # Start-of-month list\n",
    "            SOM_columns = ['TR_LTM','TR_L6M','TR_L3M','NTM_RevGrowth','NTM_EBITDA_Margin','RoE_NTM','NTM_RevGrowth_3mChg',\n",
    "                           'NTM_Rev_3mChg','NTM_EBITDA_Margin_3mChg','Sales_EV_NTM','EBITDA_EV_NTM','EY_NTM','EY_2yFwd','BY_NTM',\n",
    "                           'CoE','Implied_G','Rev_MTUM_LTM','EPS_MTUM_LTM']\n",
    "            \n",
    "            for column in SOM_columns:\n",
    "                isin_data[column + '_SOM'] = isin_data[column].shift(1)\n",
    "            \n",
    "            # Append the data to the list\n",
    "            all_isin_data.append(isin_data)\n",
    "\n",
    "# Concatenate all ISIN data into a single DataFrame\n",
    "isin_final_df = pd.concat(all_isin_data, ignore_index=True)\n",
    "\n",
    "# Merge the additional columns into the melted DataFrame using 'Date' and 'ISIN' as the keys \n",
    "df = pd.merge(df, isin_final_df, on=['Date','ISIN'])\n",
    "\n",
    "df.tail()\n",
    "\n",
    "#full_export_path = export_path + export_audit_file_name\n",
    "#df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE DATAFRAME OF EQUAL WEIGHTED AND MARKET CAP WEIGHTED AVERAGE RATIOS ####\n",
    "\n",
    "\n",
    "### Equal Weight Calculation\n",
    "EqualWeightIndex_df = df.groupby('Date')[['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevCAGR',\n",
    "                                          'NTM_EBITDA_Margin','2yFwd_EBITDA_Margin',\n",
    "                                          'RoE_LTM', 'RoE_NTM', 'RoE_2yFwd',\n",
    "                                          'CoE','Term_G','Implied_G',\n",
    "                                          'Sales_EV_NTM','EBITDA_EV_NTM',\n",
    "                                          'EY_LTM','EY_NTM','EY_2yFwd',\n",
    "                                          'BY_LTM','BY_NTM','BY_2yFwd',\n",
    "                                          'DY_LTM','DY_NTM','DY_2yFwd','NOSH_Chg_LTM',\n",
    "                                          'Rev_MTUM_LTM','EPS_MTUM_LTM']].mean().reset_index()\n",
    "\n",
    "EqualWeightIndex_df.columns = [f'{col}_Eq_Wgt' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevCAGR',\n",
    "                                          'NTM_EBITDA_Margin','2yFwd_EBITDA_Margin',\n",
    "                                          'RoE_LTM', 'RoE_NTM', 'RoE_2yFwd',\n",
    "                                          'CoE', 'Term_G','Implied_G',\n",
    "                                          'Sales_EV_NTM','EBITDA_EV_NTM',\n",
    "                                          'EY_LTM','EY_NTM','EY_2yFwd',\n",
    "                                          'BY_LTM','BY_NTM','BY_2yFwd',\n",
    "                                          'DY_LTM','DY_NTM','DY_2yFwd','NOSH_Chg_LTM',\n",
    "                                          'Rev_MTUM_LTM','EPS_MTUM_LTM'] else col for col in EqualWeightIndex_df.columns]\n",
    "\n",
    "EqualWeightIndex_df['EV_Sales_NTM_Eq_Wgt'] = 1/EqualWeightIndex_df['Sales_EV_NTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['EV_EBITDA_NTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EBITDA_EV_NTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_LTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_LTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_NTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_NTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_2yFwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_2yFwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_LTM_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_LTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_NTM_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_NTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_2yFwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_2yFwd_Eq_Wgt']\n",
    "\n",
    "\n",
    "### Median Weight Calculation\n",
    "MedianIndex_df = df.groupby('Date')[['TR',\n",
    "                                     'NTM_RevGrowth','2y_RevCAGR',\n",
    "                                     'NTM_EBITDA_Margin','2yFwd_EBITDA_Margin',\n",
    "                                     'RoE_LTM','RoE_NTM','RoE_2yFwd',\n",
    "                                     'CoE','Term_G','Implied_G',\n",
    "                                     'Sales_EV_NTM','EBITDA_EV_NTM',\n",
    "                                     'EY_LTM','EY_NTM','EY_2yFwd',\n",
    "                                     'BY_LTM','BY_NTM','BY_2yFwd',\n",
    "                                     'DY_LTM','DY_NTM','DY_2yFwd','NOSH_Chg_LTM',\n",
    "                                     'Rev_MTUM_LTM','EPS_MTUM_LTM']].median().reset_index()\n",
    "\n",
    "MedianIndex_df.columns = [f'{col}_Median' if col in ['TR',\n",
    "                                     'NTM_RevGrowth','2y_RevCAGR',\n",
    "                                     'NTM_EBITDA_Margin','2yFwd_EBITDA_Margin',\n",
    "                                     'RoE_LTM', 'RoE_NTM', 'RoE_2yFwd',\n",
    "                                     'CoE', 'Term_G','Implied_G',\n",
    "                                     'Sales_EV_NTM','EBITDA_EV_NTM',\n",
    "                                     'EY_LTM','EY_NTM','EY_2yFwd',\n",
    "                                     'BY_LTM','BY_NTM','BY_2yFwd',\n",
    "                                     'DY_LTM','DY_NTM','DY_2yFwd','NOSH_Chg_LTM',\n",
    "                                     'Rev_MTUM_LTM','EPS_MTUM_LTM'] else col for col in MedianIndex_df.columns]\n",
    "\n",
    "MedianIndex_df['EV_Sales_NTM_Median'] = 1/MedianIndex_df['Sales_EV_NTM_Median']\n",
    "MedianIndex_df['EV_EBITDA_NTM_Median'] = 1/MedianIndex_df['EBITDA_EV_NTM_Median']\n",
    "MedianIndex_df['PE_LTM_Median'] = 1/MedianIndex_df['EY_LTM_Median']\n",
    "MedianIndex_df['PE_NTM_Median'] = 1/MedianIndex_df['EY_NTM_Median']\n",
    "MedianIndex_df['PE_2yFwd_Median'] = 1/MedianIndex_df['EY_2yFwd_Median']\n",
    "MedianIndex_df['PB_LTM_Median'] = 1/MedianIndex_df['BY_LTM_Median']\n",
    "MedianIndex_df['PB_NTM_Median'] = 1/MedianIndex_df['BY_NTM_Median']\n",
    "MedianIndex_df['PB_2yFwd_Median'] = 1/MedianIndex_df['BY_2yFwd_Median']\n",
    "\n",
    "### MKT CAP WEIGHTED CALCULATION\n",
    "\n",
    "# Step 1: Create a function for weighted average calculation\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    valid_entries = ~df[value_col].isna()\n",
    "    weights = df.loc[valid_entries, weight_col]\n",
    "    values = df.loc[valid_entries, value_col]\n",
    "    if weights.sum() == 0:\n",
    "        # Handle the case where denominator is zero\n",
    "        return 0\n",
    "    else:\n",
    "        weighted_avg = (weights * values).sum() / weights.sum()\n",
    "        return weighted_avg\n",
    "\n",
    "# Step 2: Create a function to calculate the market cap weighted averages\n",
    "def calculate_weighted_averages(group):\n",
    "    weighted_TR = weighted_average(group, 'TR', 'Mkt_Cap_SOM')\n",
    "    weighted_NTM_RevGrowth = weighted_average(group, 'NTM_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_2y_RevCAGR = weighted_average(group, '2y_RevCAGR', 'Mkt_Cap')\n",
    "    weighted_NTM_EBITDA_Margin = weighted_average(group, 'NTM_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_2yFwd_EBITDA_Margin = weighted_average(group, '2yFwd_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_RoE_LTM = weighted_average(group, 'RoE_LTM', 'Mkt_Cap')\n",
    "    weighted_RoE_NTM = weighted_average(group, 'RoE_NTM', 'Mkt_Cap')\n",
    "    weighted_RoE_2yFwd = weighted_average(group, 'RoE_2yFwd', 'Mkt_Cap')\n",
    "    weighted_CoE = weighted_average(group, 'CoE', 'Mkt_Cap')\n",
    "    weighted_Term_G = weighted_average(group, 'Term_G', 'Mkt_Cap')\n",
    "    weighted_Implied_G = weighted_average(group, 'Implied_G', 'Mkt_Cap')\n",
    "    weighted_Sales_EV_NTM = weighted_average(group, 'Sales_EV_NTM', 'Mkt_Cap')\n",
    "    weighted_EBITDA_EV_NTM = weighted_average(group, 'EBITDA_EV_NTM', 'Mkt_Cap')\n",
    "    weighted_EY_LTM = weighted_average(group, 'EY_LTM', 'Mkt_Cap')\n",
    "    weighted_EY_NTM = weighted_average(group, 'EY_NTM', 'Mkt_Cap')\n",
    "    weighted_EY_2yFwd = weighted_average(group, 'EY_2yFwd', 'Mkt_Cap') \n",
    "    weighted_BY_LTM = weighted_average(group, 'BY_LTM', 'Mkt_Cap')\n",
    "    weighted_BY_NTM = weighted_average(group, 'BY_NTM', 'Mkt_Cap')\n",
    "    weighted_BY_2yFwd = weighted_average(group, 'BY_2yFwd', 'Mkt_Cap') \n",
    "    weighted_DY_LTM = weighted_average(group, 'DY_LTM', 'Mkt_Cap')\n",
    "    weighted_DY_NTM = weighted_average(group, 'DY_NTM', 'Mkt_Cap')\n",
    "    weighted_DY_2yFwd = weighted_average(group, 'DY_2yFwd', 'Mkt_Cap')\n",
    "    weighted_NOSH_Chg_LTM = weighted_average(group, 'NOSH_Chg_LTM', 'Mkt_Cap')\n",
    "    weighted_Rev_MTUM_LTM = weighted_average(group, 'Rev_MTUM_LTM', 'Mkt_Cap')\n",
    "    weighted_EPS_MTUM_LTM = weighted_average(group, 'EPS_MTUM_LTM', 'Mkt_Cap')\n",
    "       \n",
    "    return pd.Series({\n",
    "        'TR_MV_Wgt': weighted_TR,\n",
    "        'NTM_RevGrowth_MV_Wgt': weighted_NTM_RevGrowth,\n",
    "        '2y_RevCAGR_MV_Wgt': weighted_2y_RevCAGR,\n",
    "        'NTM_EBITDA_Margin_MV_Wgt': weighted_NTM_EBITDA_Margin,\n",
    "        '2yFwd_EBITDA_Margin_MV_Wgt': weighted_2yFwd_EBITDA_Margin,\n",
    "        'RoE_LTM_MV_Wgt': weighted_RoE_LTM,\n",
    "        'RoE_NTM_MV_Wgt': weighted_RoE_NTM,\n",
    "        'RoE_2yFwd_MV_Wgt': weighted_RoE_2yFwd,\n",
    "        'CoE_MV_Wgt': weighted_CoE,\n",
    "        'Term_G_MV_Wgt': weighted_Term_G,\n",
    "        'Implied_G_MV_Wgt': weighted_Implied_G,\n",
    "        'EV_Sales_NTM_MV_Wgt': weighted_Sales_EV_NTM, # harmonic mean; execution of reciprocal below\n",
    "        'EV_EBITDA_NTM_MV_Wgt': weighted_EBITDA_EV_NTM, # harmonic mean; execution of reciprocal below\n",
    "        'PE_LTM_MV_Wgt': weighted_EY_LTM, # harmonic mean; execution of reciprocal below\n",
    "        'PE_NTM_MV_Wgt': weighted_EY_NTM, # harmonic mean; execution of reciprocal below\n",
    "        'PE_2yFwd_MV_Wgt': weighted_EY_2yFwd, # harmonic mean; execution of reciprocal below\n",
    "        'PB_LTM_MV_Wgt': weighted_BY_LTM, # harmonic mean; execution of reciprocal below\n",
    "        'PB_NTM_MV_Wgt': weighted_BY_NTM, # harmonic mean; execution of reciprocal below\n",
    "        'PB_2yFwd_MV_Wgt': weighted_BY_2yFwd, # harmonic mean; execution of reciprocal below\n",
    "        'DY_LTM_MV_Wgt': weighted_DY_LTM,\n",
    "        'DY_NTM_MV_Wgt': weighted_DY_NTM,\n",
    "        'DY_2yFwd_MV_Wgt': weighted_DY_2yFwd,\n",
    "        'NOSH_Chg_LTM_MV_Wgt': weighted_NOSH_Chg_LTM,\n",
    "        'Rev_MTUM_LTM_MV_Wgt': weighted_Rev_MTUM_LTM,\n",
    "        'EPS_MTUM_LTM_MV_Wgt': weighted_EPS_MTUM_LTM        \n",
    "    })\n",
    "\n",
    "# Step 3: Apply the calculation to your DataFrame\n",
    "Index_df = df.groupby('Date').apply(calculate_weighted_averages).reset_index()\n",
    "\n",
    "# Step 4: Convert multiples where necessary\n",
    "Index_df['EV_Sales_NTM_MV_Wgt'] = 1/Index_df['EV_Sales_NTM_MV_Wgt']\n",
    "Index_df['EV_EBITDA_NTM_MV_Wgt'] = 1/Index_df['EV_EBITDA_NTM_MV_Wgt']\n",
    "Index_df['PE_LTM_MV_Wgt'] = 1/Index_df['PE_LTM_MV_Wgt']\n",
    "Index_df['PE_NTM_MV_Wgt'] = 1/Index_df['PE_NTM_MV_Wgt']\n",
    "Index_df['PE_2yFwd_MV_Wgt'] = 1/Index_df['PE_2yFwd_MV_Wgt']\n",
    "Index_df['PB_LTM_MV_Wgt'] = 1/Index_df['PB_LTM_MV_Wgt']\n",
    "Index_df['PB_NTM_MV_Wgt'] = 1/Index_df['PB_NTM_MV_Wgt']\n",
    "Index_df['PB_2yFwd_MV_Wgt'] = 1/Index_df['PB_2yFwd_MV_Wgt']\n",
    "\n",
    "# Step 4: Add in the equal weighted calculations from above into the Index dataframe\n",
    "Index_df['TR_Eq_Wgt'] = EqualWeightIndex_df['TR_Eq_Wgt']\n",
    "Index_df['NTM_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['NTM_RevGrowth_Eq_Wgt']\n",
    "Index_df['2y_RevCAGR_Eq_Wgt'] = EqualWeightIndex_df['2y_RevCAGR_Eq_Wgt']\n",
    "Index_df['NTM_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['NTM_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['2yFwd_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['2yFwd_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['RoE_LTM_Eq_Wgt'] = EqualWeightIndex_df['RoE_LTM_Eq_Wgt']\n",
    "Index_df['RoE_NTM_Eq_Wgt'] = EqualWeightIndex_df['RoE_NTM_Eq_Wgt']\n",
    "Index_df['RoE_2yFwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_2yFwd_Eq_Wgt']\n",
    "Index_df['CoE_Eq_Wgt'] = EqualWeightIndex_df['CoE_Eq_Wgt']\n",
    "Index_df['Term_G_Eq_Wgt'] = EqualWeightIndex_df['Term_G_Eq_Wgt']\n",
    "Index_df['Implied_G_Eq_Wgt'] = EqualWeightIndex_df['Implied_G_Eq_Wgt']\n",
    "Index_df['EV_Sales_NTM_Eq_Wgt'] = EqualWeightIndex_df['EV_Sales_NTM_Eq_Wgt']\n",
    "Index_df['EV_EBITDA_NTM_Eq_Wgt'] = EqualWeightIndex_df['EV_EBITDA_NTM_Eq_Wgt']\n",
    "Index_df['PE_LTM_Eq_Wgt'] = EqualWeightIndex_df['PE_LTM_Eq_Wgt']\n",
    "Index_df['PE_NTM_Eq_Wgt'] = EqualWeightIndex_df['PE_NTM_Eq_Wgt']\n",
    "Index_df['PE_2yFwd_Eq_Wgt'] = EqualWeightIndex_df['PE_2yFwd_Eq_Wgt']\n",
    "Index_df['PB_LTM_Eq_Wgt'] = EqualWeightIndex_df['PB_LTM_Eq_Wgt']\n",
    "Index_df['PB_NTM_Eq_Wgt'] = EqualWeightIndex_df['PB_NTM_Eq_Wgt']\n",
    "Index_df['PB_2yFwd_Eq_Wgt'] = EqualWeightIndex_df['PB_2yFwd_Eq_Wgt']\n",
    "Index_df['DY_LTM_Eq_Wgt'] = EqualWeightIndex_df['DY_LTM_Eq_Wgt']\n",
    "Index_df['DY_NTM_Eq_Wgt'] = EqualWeightIndex_df['DY_NTM_Eq_Wgt']\n",
    "Index_df['DY_2yFwd_Eq_Wgt'] = EqualWeightIndex_df['DY_2yFwd_Eq_Wgt']\n",
    "Index_df['NOSH_Chg_LTM_Eq_Wgt'] = EqualWeightIndex_df['NOSH_Chg_LTM_Eq_Wgt']\n",
    "Index_df['Rev_MTUM_LTM_Eq_Wgt'] = EqualWeightIndex_df['Rev_MTUM_LTM_Eq_Wgt']\n",
    "Index_df['EPS_MTUM_LTM_Eq_Wgt'] = EqualWeightIndex_df['EPS_MTUM_LTM_Eq_Wgt']\n",
    "\n",
    "# Step 5: Add in the median calculations from above into the Index dataframe\n",
    "Index_df['TR_Median'] = MedianIndex_df['TR_Median']\n",
    "Index_df['NTM_RevGrowth_Median'] = MedianIndex_df['NTM_RevGrowth_Median']\n",
    "Index_df['2y_RevCAGR_Median'] = MedianIndex_df['2y_RevCAGR_Median']\n",
    "Index_df['NTM_EBITDA_Margin_Median'] = MedianIndex_df['NTM_EBITDA_Margin_Median']\n",
    "Index_df['2yFwd_EBITDA_Margin_Median'] = MedianIndex_df['2yFwd_EBITDA_Margin_Median']\n",
    "Index_df['RoE_LTM_Median'] = MedianIndex_df['RoE_LTM_Median']\n",
    "Index_df['RoE_NTM_Median'] = MedianIndex_df['RoE_NTM_Median']\n",
    "Index_df['RoE_2yFwd_Median'] = MedianIndex_df['RoE_2yFwd_Median']\n",
    "Index_df['CoE_Median'] = MedianIndex_df['CoE_Median']\n",
    "Index_df['Term_G_Median'] = MedianIndex_df['Term_G_Median']\n",
    "Index_df['Implied_G_Median'] = MedianIndex_df['Implied_G_Median']\n",
    "Index_df['EV_Sales_NTM_Median'] = MedianIndex_df['EV_Sales_NTM_Median']\n",
    "Index_df['EV_EBITDA_NTM_Median'] = MedianIndex_df['EV_EBITDA_NTM_Median']\n",
    "Index_df['PE_LTM_Median'] = MedianIndex_df['PE_LTM_Median']\n",
    "Index_df['PE_NTM_Median'] = MedianIndex_df['PE_NTM_Median']\n",
    "Index_df['PE_2yFwd_Median'] = MedianIndex_df['PE_2yFwd_Median']\n",
    "Index_df['PB_LTM_Median'] = MedianIndex_df['PB_LTM_Median']\n",
    "Index_df['PB_NTM_Median'] = MedianIndex_df['PB_NTM_Median']\n",
    "Index_df['PB_2yFwd_Median'] = MedianIndex_df['PB_2yFwd_Median']\n",
    "Index_df['DY_LTM_Median'] = MedianIndex_df['DY_LTM_Median']\n",
    "Index_df['DY_NTM_Median'] = MedianIndex_df['DY_NTM_Median']\n",
    "Index_df['DY_2yFwd_Median'] = MedianIndex_df['DY_2yFwd_Median']\n",
    "Index_df['NOSH_Chg_LTM_Median'] = MedianIndex_df['NOSH_Chg_LTM_Median']\n",
    "Index_df['Rev_MTUM_LTM_Median'] = MedianIndex_df['Rev_MTUM_LTM_Median']\n",
    "Index_df['EPS_MTUM_LTM_Median'] = MedianIndex_df['EPS_MTUM_LTM_Median']\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#Index_df.tail()\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_index_file_name \n",
    "Index_df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94420f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LONG / SHORT RETURNS BY VARIABLE ###\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                  'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','RoE_NTM_SOM','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                  'NTM_EBITDA_Margin_3mChg_SOM','Sales_EV_NTM_SOM',\n",
    "                  'EBITDA_EV_NTM_SOM','EY_NTM_SOM','EY_2yFwd_SOM','BY_NTM_SOM','CoE_SOM','Implied_G_SOM',\n",
    "                  'Rev_MTUM_LTM_SOM','EPS_MTUM_LTM_SOM']            \n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "LS_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    df['TR'] = pd.to_numeric(df['TR'], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean TR where target_column is above the median\n",
    "        long_mean_tr = group[group[target_column] > median_value]['TR'].mean()\n",
    "        \n",
    "        # Short: mean TR where target_column is below the median\n",
    "        short_mean_tr = group[group[target_column] < median_value]['TR'].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'Long_{target_column}': long_mean_tr,  # Dynamically naming the column\n",
    "            f'Short_{target_column}': short_mean_tr  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'LS_{target_column}'] = (1 + target_df[f'Long_{target_column}']) / (1 + target_df[f'Short_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    LS_results_df = pd.merge(LS_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(LS_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_LS_file_name \n",
    "LS_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ff0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALUATION DISPERSION BY VARIABLE ###\n",
    "\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['NTM_RevGrowth', '2y_RevCAGR',\n",
    "                  'NTM_EBITDA_Margin','2yFwd_EBITDA_Margin',\n",
    "                  'RoE_NTM','RoE_2yFwd',\n",
    "                  'CoE','Term_G','Implied_G',\n",
    "                  'Sales_EV_NTM','EBITDA_EV_NTM','EY_NTM','EY_2yFwd',\n",
    "                  'Rev_MTUM_LTM','EPS_MTUM_LTM']\n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "dispersion_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean of target_column where target_column is above the median\n",
    "        long_mean_target = group[group[target_column] > median_value][target_column].mean()\n",
    "        \n",
    "        # Short: mean of target_column where target_column is below the median\n",
    "        short_mean_target = group[group[target_column] < median_value][target_column].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'above_{target_column}': long_mean_target,  # Dynamically naming the column\n",
    "            f'below_{target_column}': short_mean_target  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'spread_{target_column}'] = (1 + target_df[f'above_{target_column}']) / (1 + target_df[f'below_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    dispersion_results_df = pd.merge(dispersion_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(dispersion_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_dispersion_file_name \n",
    "dispersion_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c10ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine stock by stock data for a single month\n",
    "examine_data = df[(df['Date'] >= '2020-08-31') & (df['Date'] <= '2020-08-31')]\n",
    "\n",
    "# Export to xlsx\n",
    "full_export_path = export_path + export_examine_CSV_file_name\n",
    "examine_data.to_excel(full_export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
