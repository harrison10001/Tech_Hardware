{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a1f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mkt_Cap</th>\n",
       "      <th>TR</th>\n",
       "      <th>PCH</th>\n",
       "      <th>NTM_RevGrowth</th>\n",
       "      <th>2y_RevGrowth</th>\n",
       "      <th>NTM_EBITDA_Margin</th>\n",
       "      <th>2y_EBITDA_Margin</th>\n",
       "      <th>RoE_TTM</th>\n",
       "      <th>...</th>\n",
       "      <th>NTM_RoE_SOM</th>\n",
       "      <th>NTM_RevGrowth_3mChg_SOM</th>\n",
       "      <th>NTM_Rev_3mChg_SOM</th>\n",
       "      <th>NTM_EBITDA_Margin_3mChg_SOM</th>\n",
       "      <th>Sales_EV_1y_Fwd_SOM</th>\n",
       "      <th>EBITDA_EV_1y_Fwd_SOM</th>\n",
       "      <th>EY_1y_Fwd_SOM</th>\n",
       "      <th>EY_2y_Fwd_SOM</th>\n",
       "      <th>BY_1y_Fwd_SOM</th>\n",
       "      <th>CoE_SOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0214411003</td>\n",
       "      <td>11136.04</td>\n",
       "      <td>0.129999</td>\n",
       "      <td>0.123899</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.322954</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.141194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159744</td>\n",
       "      <td>-0.014959</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.235603</td>\n",
       "      <td>0.079404</td>\n",
       "      <td>0.055026</td>\n",
       "      <td>0.062253</td>\n",
       "      <td>0.344342</td>\n",
       "      <td>0.084616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0326541051</td>\n",
       "      <td>18242.66</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>0.123501</td>\n",
       "      <td>0.119085</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>0.388043</td>\n",
       "      <td>0.392229</td>\n",
       "      <td>0.166645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184237</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.226310</td>\n",
       "      <td>0.085111</td>\n",
       "      <td>0.055753</td>\n",
       "      <td>0.061017</td>\n",
       "      <td>0.302593</td>\n",
       "      <td>0.084858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0382221051</td>\n",
       "      <td>30778.86</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.096760</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.250525</td>\n",
       "      <td>0.277347</td>\n",
       "      <td>0.168763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181813</td>\n",
       "      <td>-0.003712</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.377533</td>\n",
       "      <td>0.096815</td>\n",
       "      <td>0.059545</td>\n",
       "      <td>0.071870</td>\n",
       "      <td>0.327460</td>\n",
       "      <td>0.087613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>US0420681068</td>\n",
       "      <td>25157.13</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>0.141546</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.136330</td>\n",
       "      <td>0.556584</td>\n",
       "      <td>0.555808</td>\n",
       "      <td>0.270009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740495</td>\n",
       "      <td>-0.026942</td>\n",
       "      <td>-0.005572</td>\n",
       "      <td>-0.022268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.041845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>USN070592100</td>\n",
       "      <td>47188.38</td>\n",
       "      <td>0.036564</td>\n",
       "      <td>0.035982</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>0.294703</td>\n",
       "      <td>0.285956</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169250</td>\n",
       "      <td>-0.016665</td>\n",
       "      <td>-0.040214</td>\n",
       "      <td>-0.003101</td>\n",
       "      <td>0.186005</td>\n",
       "      <td>0.052475</td>\n",
       "      <td>0.039667</td>\n",
       "      <td>0.046142</td>\n",
       "      <td>0.234332</td>\n",
       "      <td>0.076131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          ISIN   Mkt_Cap        TR       PCH  NTM_RevGrowth  \\\n",
       "0 2015-02-28  US0214411003  11136.04  0.129999  0.123899       0.035620   \n",
       "1 2015-02-28  US0326541051  18242.66  0.131119  0.123501       0.119085   \n",
       "2 2015-02-28  US0382221051  30778.86  0.101307  0.096760       0.081776   \n",
       "3 2015-02-28  US0420681068  25157.13  0.141548  0.141546       0.136868   \n",
       "4 2015-02-28  USN070592100  47188.38  0.036564  0.035982       0.048862   \n",
       "\n",
       "   2y_RevGrowth  NTM_EBITDA_Margin  2y_EBITDA_Margin   RoE_TTM  ...  \\\n",
       "0      0.051850           0.322954          0.345238  0.141194  ...   \n",
       "1      0.087081           0.388043          0.392229  0.166645  ...   \n",
       "2      0.066467           0.250525          0.277347  0.168763  ...   \n",
       "3      0.136330           0.556584          0.555808  0.270009  ...   \n",
       "4      0.076889           0.294703          0.285956  0.173400  ...   \n",
       "\n",
       "   NTM_RoE_SOM  NTM_RevGrowth_3mChg_SOM  NTM_Rev_3mChg_SOM  \\\n",
       "0     0.159744                -0.014959           0.010868   \n",
       "1     0.184237                -0.026266           0.011688   \n",
       "2     0.181813                -0.003712           0.020253   \n",
       "3     0.740495                -0.026942          -0.005572   \n",
       "4     0.169250                -0.016665          -0.040214   \n",
       "\n",
       "   NTM_EBITDA_Margin_3mChg_SOM  Sales_EV_1y_Fwd_SOM  EBITDA_EV_1y_Fwd_SOM  \\\n",
       "0                     0.001948             0.235603              0.079404   \n",
       "1                     0.007748             0.226310              0.085111   \n",
       "2                     0.008553             0.377533              0.096815   \n",
       "3                    -0.022268                  NaN                   NaN   \n",
       "4                    -0.003101             0.186005              0.052475   \n",
       "\n",
       "   EY_1y_Fwd_SOM  EY_2y_Fwd_SOM  BY_1y_Fwd_SOM   CoE_SOM  \n",
       "0       0.055026       0.062253       0.344342  0.084616  \n",
       "1       0.055753       0.061017       0.302593  0.084858  \n",
       "2       0.059545       0.071870       0.327460  0.087613  \n",
       "3       0.030999       0.036403       0.041845       NaN  \n",
       "4       0.039667       0.046142       0.234332  0.076131  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## Define file path depending on which index to examine\n",
    "\n",
    "## SOX\n",
    "index_file_path = \"H:/Tech Hardware Shared/$Mike/Quant/SOX_Constit.csv\"\n",
    "csv_directory = \"H:/Tech Hardware Shared/$Mike/Quant/CSV_files\"\n",
    "export_path = \"H:/Tech Hardware Shared/$Mike/Quant/Python_Outputs/\"\n",
    "export_audit_file_name = 'SOX_audit.xlsx'\n",
    "export_index_file_name = 'SOX_Index_Avgs.xlsx'\n",
    "export_LS_file_name = 'SOX_LS.xlsx'\n",
    "export_dispersion_file_name = 'SOX_dispersion.xlsx'\n",
    "export_examine_CSV_file_name = 'SOX_indiv_CSV.xlsx'\n",
    "\n",
    "##### CREATING DATABASE DATAFRAME ######\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(index_file_path, header=0)\n",
    "# Convert the column names to datetime with the given format\n",
    "df.columns = pd.to_datetime(df.columns, format='%d-%b-%y')\n",
    "\n",
    "# Melt the DataFrame to reshape it\n",
    "df = pd.melt(df, id_vars=[], var_name='Date', value_name='ISIN')\n",
    "df['Date'] = df['Date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# Use a placeholder for NaN values in the 'ISIN' column \n",
    "df['ISIN'].fillna('placeholder', inplace=True)\n",
    "\n",
    "# Create a list to store each ISIN's data\n",
    "all_isin_data = []\n",
    "\n",
    "# Iterate through each ISIN in the 'ISIN' column \n",
    "for isin in df['ISIN'].unique():\n",
    "    # Skip if the ISIN is 'placeholder'\n",
    "    if isin != 'placeholder':\n",
    "        # Construct the file path for the CSV file\n",
    "        index_file_path = os.path.join(csv_directory, f'{isin}.csv')\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(index_file_path):        \n",
    "            # Read the CSV file\n",
    "            isin_data = pd.read_csv(index_file_path, header=0)  # Assuming header is in row 2 and 'Date' is the label\n",
    "            isin_data['Date'] = pd.to_datetime(isin_data['Date'], unit='D', origin='1899-12-30')\n",
    "            isin_data['Date'] = isin_data['Date'] + pd.offsets.MonthEnd(0)\n",
    "            isin_data['ISIN'] = isin\n",
    "            # Convert all data columns to numeric\n",
    "                                  \n",
    "            numeric_columns = ['Mkt_Cap','TR', 'PCH',\n",
    "                               'NTM_RevGrowth','2y_RevGrowth',\n",
    "                               'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                               'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                               'CoE', 'Assumed_G', \n",
    "                               'Sales_EV_1y_Fwd', 'EV_Sales_1y_Fwd', 'EBITDA_EV_1y_Fwd','EV_EBITDA_1y_Fwd',\n",
    "                               'EY_TTM','PE_TTM', 'EY_1y_Fwd','PE_1y_Fwd','EY_2y_Fwd','PE_2y_Fwd',\n",
    "                               'BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd',\n",
    "                               'DY_TTM','DY_1y_Fwd','DY_2y_Fwd',\n",
    "                               'NOSH_Chg_LTM',\n",
    "                               'TIME',\n",
    "                               'Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                               'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM',\n",
    "                               'NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                               'NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                               'Sales_EV_1y_Fwd_SOM','EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "            isin_data[numeric_columns] = isin_data[numeric_columns].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            # nix out negative BVPS data & other floors / ceilings\n",
    "            neg_cols = ['BY_TTM','PB_TTM', 'BY_1y_Fwd','PB_1y_Fwd','BY_2y_Fwd','PB_2y_Fwd','CoE']\n",
    "            for col in neg_cols:\n",
    "                isin_data[col] = np.where(isin_data[col] < 0, np.nan, isin_data[col])\n",
    "            \n",
    "            upper_bound = 0.5 # Max CoE = 50%\n",
    "            isin_data['CoE'] = isin_data['CoE'].clip(upper=upper_bound)\n",
    "                                   \n",
    "            lower_bound = -0.02 # Max multiple = -50x\n",
    "            upper_bound = 1 # Min multiple = 1x\n",
    "            isin_data['Sales_EV_1y_Fwd'] = isin_data['Sales_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EBITDA_EV_1y_Fwd'] = isin_data['EBITDA_EV_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_TTM'] = isin_data['EY_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_1y_Fwd'] = isin_data['EY_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['EY_2y_Fwd'] = isin_data['EY_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            \n",
    "            lower_bound = -0.5\n",
    "            upper_bound = 1.5\n",
    "            isin_data['RoE_TTM'] = isin_data['RoE_TTM'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_1y_Fwd'] = isin_data['RoE_1y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "            isin_data['RoE_2y_Fwd'] = isin_data['RoE_2y_Fwd'].clip(upper=upper_bound,lower=lower_bound)\n",
    "                                        \n",
    "            # Append the data to the list\n",
    "            all_isin_data.append(isin_data)\n",
    "\n",
    "# Concatenate all ISIN data into a single DataFrame\n",
    "isin_final_df = pd.concat(all_isin_data, ignore_index=True)\n",
    "\n",
    "# Merge the additional columns into the melted DataFrame using 'Date' and 'ISIN' as the keys \n",
    "df = pd.merge(df, isin_final_df, on=['Date','ISIN'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "#full_export_path = export_path + export_audit_file_name\n",
    "#df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE DATAFRAME OF EQUAL WEIGHTED AND MARKET CAP WEIGHTED AVERAGE RATIOS ####\n",
    "\n",
    "\n",
    "### Equal Weight Calculation\n",
    "EqualWeightIndex_df = df.groupby('Date')[['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].mean().reset_index()\n",
    "\n",
    "EqualWeightIndex_df.columns = [f'{col}_Eq_Wgt' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in EqualWeightIndex_df.columns]\n",
    "\n",
    "EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['Sales_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EBITDA_EV_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['EY_2y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_TTM_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_TTM_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_1y_Fwd_Eq_Wgt']\n",
    "EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt'] = 1/EqualWeightIndex_df['BY_2y_Fwd_Eq_Wgt']\n",
    "\n",
    "\n",
    "### Median Weight Calculation\n",
    "MedianIndex_df = df.groupby('Date')[['TR',\n",
    "                                     'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                     'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                     'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                     'CoE', 'Assumed_G',\n",
    "                                     'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                     'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                     'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                     'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM']].median().reset_index()\n",
    "\n",
    "MedianIndex_df.columns = [f'{col}_Median' if col in ['TR',\n",
    "                                          'NTM_RevGrowth','2y_RevGrowth','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                                          'NTM_EBITDA_Margin','2y_EBITDA_Margin','NTM_EBITDA_Margin_3mChg_SOM',\n",
    "                                          'RoE_TTM', 'RoE_1y_Fwd', 'RoE_2y_Fwd',\n",
    "                                          'CoE', 'Assumed_G',\n",
    "                                          'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd',\n",
    "                                          'EY_TTM','EY_1y_Fwd','EY_2y_Fwd',\n",
    "                                          'BY_TTM','BY_1y_Fwd','BY_2y_Fwd',\n",
    "                                          'DY_TTM','DY_1y_Fwd','DY_2y_Fwd','NOSH_Chg_LTM'] else col for col in MedianIndex_df.columns]\n",
    "\n",
    "MedianIndex_df['EV_Sales_1y_Fwd_Median'] = 1/MedianIndex_df['Sales_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['EV_EBITDA_1y_Fwd_Median'] = 1/MedianIndex_df['EBITDA_EV_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_TTM_Median'] = 1/MedianIndex_df['EY_TTM_Median']\n",
    "MedianIndex_df['PE_1y_Fwd_Median'] = 1/MedianIndex_df['EY_1y_Fwd_Median']\n",
    "MedianIndex_df['PE_2y_Fwd_Median'] = 1/MedianIndex_df['EY_2y_Fwd_Median']\n",
    "MedianIndex_df['PB_TTM_Median'] = 1/MedianIndex_df['BY_TTM_Median']\n",
    "MedianIndex_df['PB_1y_Fwd_Median'] = 1/MedianIndex_df['BY_1y_Fwd_Median']\n",
    "MedianIndex_df['PB_2y_Fwd_Median'] = 1/MedianIndex_df['BY_2y_Fwd_Median']\n",
    "\n",
    "### MKT CAP WEIGHTED CALCULATION\n",
    "\n",
    "# Step 1: Create a function for weighted average calculation\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    valid_entries = ~df[value_col].isna()\n",
    "    weights = df.loc[valid_entries, weight_col]\n",
    "    values = df.loc[valid_entries, value_col]\n",
    "    if weights.sum() == 0:\n",
    "        # Handle the case where denominator is zero\n",
    "        return 0\n",
    "    else:\n",
    "        weighted_avg = (weights * values).sum() / weights.sum()\n",
    "        return weighted_avg\n",
    "\n",
    "# Step 2: Create a function to calculate the market cap weighted averages\n",
    "def calculate_weighted_averages(group):\n",
    "    weighted_TR = weighted_average(group, 'TR', 'Mkt_Cap_SOM')\n",
    "    weighted_NTM_RevGrowth = weighted_average(group, 'NTM_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_2y_RevGrowth = weighted_average(group, '2y_RevGrowth', 'Mkt_Cap')\n",
    "    weighted_NTM_EBITDA_Margin = weighted_average(group, 'NTM_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_2y_EBITDA_Margin = weighted_average(group, '2y_EBITDA_Margin', 'Mkt_Cap')\n",
    "    weighted_RoE_TTM = weighted_average(group, 'RoE_TTM', 'Mkt_Cap')\n",
    "    weighted_RoE_1y_Fwd = weighted_average(group, 'RoE_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_RoE_2y_Fwd = weighted_average(group, 'RoE_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_CoE = weighted_average(group, 'CoE', 'Mkt_Cap')\n",
    "    weighted_Assumed_G = weighted_average(group, 'Assumed_G', 'Mkt_Cap')\n",
    "    weighted_Sales_EV_1y_Fwd = weighted_average(group, 'Sales_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EBITDA_EV_1y_Fwd = weighted_average(group, 'EBITDA_EV_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_TTM = weighted_average(group, 'EY_TTM', 'Mkt_Cap')\n",
    "    weighted_EY_1y_Fwd = weighted_average(group, 'EY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_EY_2y_Fwd = weighted_average(group, 'EY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_BY_TTM = weighted_average(group, 'BY_TTM', 'Mkt_Cap')\n",
    "    weighted_BY_1y_Fwd = weighted_average(group, 'BY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_BY_2y_Fwd = weighted_average(group, 'BY_2y_Fwd', 'Mkt_Cap') \n",
    "    weighted_DY_TTM = weighted_average(group, 'DY_TTM', 'Mkt_Cap')\n",
    "    weighted_DY_1y_Fwd = weighted_average(group, 'DY_1y_Fwd', 'Mkt_Cap')\n",
    "    weighted_DY_2y_Fwd = weighted_average(group, 'DY_2y_Fwd', 'Mkt_Cap')\n",
    "    weighted_NOSH_Chg_LTM = weighted_average(group, 'NOSH_Chg_LTM', 'Mkt_Cap')\n",
    "    \n",
    "    \n",
    "    return pd.Series({\n",
    "        'TR_MV_Wgt': weighted_TR,\n",
    "        'NTM_RevGrowth_MV_Wgt': weighted_NTM_RevGrowth,\n",
    "        '2y_RevGrowth_MV_Wgt': weighted_2y_RevGrowth,\n",
    "        'NTM_EBITDA_Margin_MV_Wgt': weighted_NTM_EBITDA_Margin,\n",
    "        '2y_EBITDA_Margin_MV_Wgt': weighted_2y_EBITDA_Margin,\n",
    "        'RoE_TTM_MV_Wgt': weighted_RoE_TTM,\n",
    "        'RoE_1y_Fwd_MV_Wgt': weighted_RoE_1y_Fwd,\n",
    "        'RoE_2y_Fwd_MV_Wgt': weighted_RoE_2y_Fwd,\n",
    "        'CoE_MV_Wgt': weighted_CoE,\n",
    "        'Assumed_G_MV_Wgt': weighted_Assumed_G,\n",
    "        'EV_Sales_1y_Fwd_MV_Wgt': weighted_Sales_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'EV_EBITDA_1y_Fwd_MV_Wgt': weighted_EBITDA_EV_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_TTM_MV_Wgt': weighted_EY_TTM, # execution of reciprocal below\n",
    "        'PE_1y_Fwd_MV_Wgt': weighted_EY_1y_Fwd, # execution of reciprocal below\n",
    "        'PE_2y_Fwd_MV_Wgt': weighted_EY_2y_Fwd, # execution of reciprocal below\n",
    "        'PB_TTM_MV_Wgt': weighted_BY_TTM, # execution of reciprocal below\n",
    "        'PB_1y_Fwd_MV_Wgt': weighted_BY_1y_Fwd, # execution of reciprocal below\n",
    "        'PB_2y_Fwd_MV_Wgt': weighted_BY_2y_Fwd, # execution of reciprocal below\n",
    "        'DY_TTM_MV_Wgt': weighted_DY_TTM,\n",
    "        'DY_1y_Fwd_MV_Wgt': weighted_DY_1y_Fwd,\n",
    "        'DY_2y_Fwd_MV_Wgt': weighted_DY_2y_Fwd,\n",
    "        'NOSH_Chg_LTM_MV_Wgt': weighted_NOSH_Chg_LTM\n",
    "    })\n",
    "\n",
    "# Step 3: Apply the calculation to your DataFrame\n",
    "Index_df = df.groupby('Date').apply(calculate_weighted_averages).reset_index()\n",
    "Index_df['EV_Sales_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_Sales_1y_Fwd_MV_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_MV_Wgt'] = 1/Index_df['EV_EBITDA_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_TTM_MV_Wgt'] = 1/Index_df['PE_TTM_MV_Wgt']\n",
    "Index_df['PE_1y_Fwd_MV_Wgt'] = 1/Index_df['PE_1y_Fwd_MV_Wgt']\n",
    "Index_df['PE_2y_Fwd_MV_Wgt'] = 1/Index_df['PE_2y_Fwd_MV_Wgt']\n",
    "Index_df['PB_TTM_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_1y_Fwd_MV_Wgt'] = 1/Index_df['PB_1y_Fwd_MV_Wgt']\n",
    "Index_df['PB_2y_Fwd_MV_Wgt'] = 1/Index_df['PB_2y_Fwd_MV_Wgt']\n",
    "\n",
    "# Step 4: Add in the equal weighted calculations from above into the Index dataframe\n",
    "Index_df['TR_Eq_Wgt'] = EqualWeightIndex_df['TR_Eq_Wgt']\n",
    "Index_df['NTM_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['NTM_RevGrowth_Eq_Wgt']\n",
    "Index_df['2y_RevGrowth_Eq_Wgt'] = EqualWeightIndex_df['2y_RevGrowth_Eq_Wgt']\n",
    "Index_df['NTM_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['NTM_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['2y_EBITDA_Margin_Eq_Wgt'] = EqualWeightIndex_df['2y_EBITDA_Margin_Eq_Wgt']\n",
    "Index_df['RoE_TTM_Eq_Wgt'] = EqualWeightIndex_df['RoE_TTM_Eq_Wgt']\n",
    "Index_df['RoE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['RoE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['RoE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['CoE_Eq_Wgt'] = EqualWeightIndex_df['CoE_Eq_Wgt']\n",
    "Index_df['Assumed_G_Eq_Wgt'] = EqualWeightIndex_df['Assumed_G_Eq_Wgt']\n",
    "Index_df['EV_Sales_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_Sales_1y_Fwd_Eq_Wgt']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['EV_EBITDA_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_TTM_Eq_Wgt'] = EqualWeightIndex_df['PE_TTM_Eq_Wgt']\n",
    "Index_df['PE_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PE_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PE_2y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_TTM_Eq_Wgt'] = EqualWeightIndex_df['PB_TTM_Eq_Wgt']\n",
    "Index_df['PB_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_1y_Fwd_Eq_Wgt']\n",
    "Index_df['PB_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['PB_2y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_TTM_Eq_Wgt'] = EqualWeightIndex_df['DY_TTM_Eq_Wgt']\n",
    "Index_df['DY_1y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_1y_Fwd_Eq_Wgt']\n",
    "Index_df['DY_2y_Fwd_Eq_Wgt'] = EqualWeightIndex_df['DY_2y_Fwd_Eq_Wgt']\n",
    "Index_df['NOSH_Chg_LTM_Eq_Wgt'] = EqualWeightIndex_df['NOSH_Chg_LTM_Eq_Wgt']\n",
    "\n",
    "# Step 5: Add in the median calculations from above into the Index dataframe\n",
    "Index_df['TR_Median'] = MedianIndex_df['TR_Median']\n",
    "Index_df['NTM_RevGrowth_Median'] = MedianIndex_df['NTM_RevGrowth_Median']\n",
    "Index_df['2y_RevGrowth_Median'] = MedianIndex_df['2y_RevGrowth_Median']\n",
    "Index_df['NTM_EBITDA_Margin_Median'] = MedianIndex_df['NTM_EBITDA_Margin_Median']\n",
    "Index_df['2y_EBITDA_Margin_Median'] = MedianIndex_df['2y_EBITDA_Margin_Median']\n",
    "Index_df['RoE_TTM_Median'] = MedianIndex_df['RoE_TTM_Median']\n",
    "Index_df['RoE_1y_Fwd_Median'] = MedianIndex_df['RoE_1y_Fwd_Median']\n",
    "Index_df['RoE_2y_Fwd_Median'] = MedianIndex_df['RoE_2y_Fwd_Median']\n",
    "Index_df['CoE_Median'] = MedianIndex_df['CoE_Median']\n",
    "Index_df['Assumed_G_Median'] = MedianIndex_df['Assumed_G_Median']\n",
    "Index_df['EV_Sales_1y_Fwd_Median'] = MedianIndex_df['EV_Sales_1y_Fwd_Median']\n",
    "Index_df['EV_EBITDA_1y_Fwd_Median'] = MedianIndex_df['EV_EBITDA_1y_Fwd_Median']\n",
    "Index_df['PE_TTM_Median'] = MedianIndex_df['PE_TTM_Median']\n",
    "Index_df['PE_1y_Fwd_Median'] = MedianIndex_df['PE_1y_Fwd_Median']\n",
    "Index_df['PE_2y_Fwd_Median'] = MedianIndex_df['PE_2y_Fwd_Median']\n",
    "Index_df['PB_TTM_Median'] = MedianIndex_df['PB_TTM_Median']\n",
    "Index_df['PB_1y_Fwd_Median'] = MedianIndex_df['PB_1y_Fwd_Median']\n",
    "Index_df['PB_2y_Fwd_Median'] = MedianIndex_df['PB_2y_Fwd_Median']\n",
    "Index_df['DY_TTM_Median'] = MedianIndex_df['DY_TTM_Median']\n",
    "Index_df['DY_1y_Fwd_Median'] = MedianIndex_df['DY_1y_Fwd_Median']\n",
    "Index_df['DY_2y_Fwd_Median'] = MedianIndex_df['DY_2y_Fwd_Median']\n",
    "Index_df['NOSH_Chg_LTM_Median'] = MedianIndex_df['NOSH_Chg_LTM_Median']\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#Index_df.tail()\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_index_file_name \n",
    "Index_df.to_excel(full_export_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94420f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LONG / SHORT RETURNS BY VARIABLE ###\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['Mkt_Cap_SOM','TR_LTM_SOM','TR_L6M_SOM','TR_L3M_SOM',\n",
    "                  'NTM_RevGrowth_SOM','NTM_EBITDA_Margin_SOM','NTM_RoE_SOM','NTM_RevGrowth_3mChg_SOM','NTM_Rev_3mChg_SOM',\n",
    "                  'NTM_EBITDA_Margin_3mChg_SOM','Sales_EV_1y_Fwd_SOM',\n",
    "                  'EBITDA_EV_1y_Fwd_SOM','EY_1y_Fwd_SOM','EY_2y_Fwd_SOM','BY_1y_Fwd_SOM','CoE_SOM']            \n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "LS_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    df['TR'] = pd.to_numeric(df['TR'], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean TR where target_column is above the median\n",
    "        long_mean_tr = group[group[target_column] > median_value]['TR'].mean()\n",
    "        \n",
    "        # Short: mean TR where target_column is below the median\n",
    "        short_mean_tr = group[group[target_column] < median_value]['TR'].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'Long_{target_column}': long_mean_tr,  # Dynamically naming the column\n",
    "            f'Short_{target_column}': short_mean_tr  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'LS_{target_column}'] = (1 + target_df[f'Long_{target_column}']) / (1 + target_df[f'Short_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    LS_results_df = pd.merge(LS_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(LS_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_LS_file_name \n",
    "LS_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6ff0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALUATION DISPERSION BY VARIABLE ###\n",
    "\n",
    "\n",
    "# List of target columns you want to iterate over\n",
    "target_columns = ['NTM_RevGrowth', '2y_RevGrowth',\n",
    "                  'NTM_EBITDA_Margin','2y_EBITDA_Margin',\n",
    "                  'RoE_1y_Fwd','RoE_2y_Fwd',\n",
    "                  'CoE','Assumed_G',\n",
    "                  'Sales_EV_1y_Fwd','EBITDA_EV_1y_Fwd','EY_1y_Fwd','EY_2y_Fwd',]\n",
    "\n",
    "# Initialize the final result DataFrame with unique Dates\n",
    "dispersion_results_df = pd.DataFrame(df['Date'].unique(), columns=['Date'])\n",
    "\n",
    "# Loop over each target column\n",
    "for target_column in target_columns:\n",
    "    \n",
    "    # Ensure both the target column and 'TR' are numeric\n",
    "    df[target_column] = pd.to_numeric(df[target_column], errors='coerce')\n",
    "    \n",
    "    # List to collect results for this target column\n",
    "    results = []\n",
    "    \n",
    "    # Group by 'Date' and compute median and means for 'Long_' and 'Short_' prefixed series\n",
    "    for date, group in df.groupby('Date'):\n",
    "        median_value = group[target_column].median()\n",
    "        \n",
    "        # Long: mean of target_column where target_column is above the median\n",
    "        long_mean_target = group[group[target_column] > median_value][target_column].mean()\n",
    "        \n",
    "        # Short: mean of target_column where target_column is below the median\n",
    "        short_mean_target = group[group[target_column] < median_value][target_column].mean()\n",
    "        \n",
    "        # Append the results for each date\n",
    "        results.append({\n",
    "            'Date': date,\n",
    "            f'above_{target_column}': long_mean_target,  # Dynamically naming the column\n",
    "            f'below_{target_column}': short_mean_target  # Dynamically naming the column\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with the results for the current target column\n",
    "    target_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add the \"LS_<target_column>\" column\n",
    "    target_df[f'spread_{target_column}'] = (1 + target_df[f'above_{target_column}']) / (1 + target_df[f'below_{target_column}']) - 1\n",
    "    \n",
    "    # Merge the current results with the final results DataFrame\n",
    "    dispersion_results_df = pd.merge(dispersion_results_df, target_df, on='Date', how='left')\n",
    "\n",
    "# Output the final result\n",
    "#print(dispersion_results_df)\n",
    "\n",
    "# Export to xlxs\n",
    "full_export_path = export_path + export_dispersion_file_name \n",
    "dispersion_results_df.to_excel(full_export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine stock by stock data for a single month\n",
    "examine_data = df[(df['Date'] >= '2024-09-30') & (df['Date'] <= '2024-09-30')]\n",
    "\n",
    "# Export to xlsx\n",
    "full_export_path = export_path + export_examine_CSV_file_name\n",
    "examine_data.to_excel(full_export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
